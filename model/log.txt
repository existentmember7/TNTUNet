[20:52:28.490] Namespace(base_lr=0.01, batch_size=1, channels=4, deterministic=1, image_height=256, image_width=256, max_epochs=150, max_iterations=30000, model_path='/home/han/Documents/han/TNTUNet/model/', num_classes=2, save_interval=50, seed=42, testing_data_path=None, training_data_path='/home/han/Documents/han/TNTUNet/datasets/train/', validation_data_path=None)
[20:52:28.492] 200 iterations per epoch. 6000000 max iterations 
[20:52:28.818] iteration 1 : loss : 0.622453, loss_ce: 0.720597
[20:52:29.101] iteration 2 : loss : 0.406753, loss_ce: 0.359060
[20:52:29.365] iteration 3 : loss : 0.483752, loss_ce: 0.436378
[20:52:29.629] iteration 4 : loss : 0.443103, loss_ce: 0.361438
[20:52:29.896] iteration 5 : loss : 0.685712, loss_ce: 0.818877
[20:52:30.161] iteration 6 : loss : 0.601118, loss_ce: 0.662577
[20:52:30.428] iteration 7 : loss : 0.668690, loss_ce: 0.788942
[20:52:30.694] iteration 8 : loss : 0.676810, loss_ce: 0.802859
[20:52:30.962] iteration 9 : loss : 0.838662, loss_ce: 1.094503
[20:52:31.228] iteration 10 : loss : 0.517283, loss_ce: 0.500558
[20:52:31.497] iteration 11 : loss : 0.527787, loss_ce: 0.548979
[20:52:31.762] iteration 12 : loss : 0.447450, loss_ce: 0.569990
[20:52:32.025] iteration 13 : loss : 0.637052, loss_ce: 0.772746
[20:52:32.290] iteration 14 : loss : 0.461340, loss_ce: 0.552703
[20:52:32.562] iteration 15 : loss : 0.466231, loss_ce: 0.472308
[20:52:32.837] iteration 16 : loss : 0.371770, loss_ce: 0.277047
[20:52:33.103] iteration 17 : loss : 0.521530, loss_ce: 0.510318
[20:52:33.368] iteration 18 : loss : 0.394794, loss_ce: 0.281369
[20:52:33.631] iteration 19 : loss : 0.447066, loss_ce: 0.378069
[20:52:33.895] iteration 20 : loss : 0.510523, loss_ce: 0.490252
[20:52:56.466] Namespace(base_lr=0.01, batch_size=1, channels=4, deterministic=1, image_height=256, image_width=256, max_epochs=150, max_iterations=30000, model_path='/home/han/Documents/han/TNTUNet/model/', num_classes=2, save_interval=50, seed=42, testing_data_path=None, training_data_path='/home/han/Documents/han/TNTUNet/datasets/train/', validation_data_path=None)
[20:52:56.468] 200 iterations per epoch. 6000000 max iterations 
[20:52:56.795] iteration 1 : loss : 0.622453, loss_ce: 0.720597
[20:52:57.097] iteration 2 : loss : 0.406753, loss_ce: 0.359060
[20:52:57.380] iteration 3 : loss : 0.483752, loss_ce: 0.436378
[20:52:57.663] iteration 4 : loss : 0.443103, loss_ce: 0.361438
[20:52:57.952] iteration 5 : loss : 0.685712, loss_ce: 0.818877
[20:52:58.242] iteration 6 : loss : 0.601118, loss_ce: 0.662577
[20:52:58.532] iteration 7 : loss : 0.668690, loss_ce: 0.788942
[20:52:58.839] iteration 8 : loss : 0.676810, loss_ce: 0.802859
[20:52:59.145] iteration 9 : loss : 0.838662, loss_ce: 1.094503
[20:52:59.454] iteration 10 : loss : 0.517283, loss_ce: 0.500558
[20:52:59.748] iteration 11 : loss : 0.527787, loss_ce: 0.548979
[20:53:00.045] iteration 12 : loss : 0.447450, loss_ce: 0.569990
[20:53:00.325] iteration 13 : loss : 0.637052, loss_ce: 0.772746
[20:53:00.595] iteration 14 : loss : 0.461340, loss_ce: 0.552703
[20:53:00.859] iteration 15 : loss : 0.466231, loss_ce: 0.472308
[20:53:01.122] iteration 16 : loss : 0.371770, loss_ce: 0.277047
[20:53:01.384] iteration 17 : loss : 0.521530, loss_ce: 0.510318
[20:53:01.646] iteration 18 : loss : 0.394794, loss_ce: 0.281369
[20:53:01.906] iteration 19 : loss : 0.447066, loss_ce: 0.378069
[20:53:02.169] iteration 20 : loss : 0.510523, loss_ce: 0.490252
[20:53:25.775] Namespace(base_lr=0.01, batch_size=1, channels=4, deterministic=1, image_height=256, image_width=256, max_epochs=150, max_iterations=30000, model_path='/home/han/Documents/han/TNTUNet/model/', num_classes=2, save_interval=50, seed=42, testing_data_path=None, training_data_path='/home/han/Documents/han/TNTUNet/datasets/train/', validation_data_path=None)
[20:53:25.777] 200 iterations per epoch. 6000000 max iterations 
[20:53:26.074] iteration 1 : loss : 0.622453, loss_ce: 0.720597
[20:53:26.343] iteration 2 : loss : 0.406753, loss_ce: 0.359060
[20:53:26.603] iteration 3 : loss : 0.483752, loss_ce: 0.436378
[20:53:26.864] iteration 4 : loss : 0.443103, loss_ce: 0.361438
[20:53:27.128] iteration 5 : loss : 0.685712, loss_ce: 0.818877
[20:53:27.388] iteration 6 : loss : 0.601119, loss_ce: 0.662577
[20:53:27.651] iteration 7 : loss : 0.668690, loss_ce: 0.788942
[20:53:27.915] iteration 8 : loss : 0.676810, loss_ce: 0.802859
[20:53:28.190] iteration 9 : loss : 0.838662, loss_ce: 1.094503
[20:53:28.453] iteration 10 : loss : 0.517283, loss_ce: 0.500558
[20:53:28.720] iteration 11 : loss : 0.527787, loss_ce: 0.548979
[20:53:28.982] iteration 12 : loss : 0.447450, loss_ce: 0.569990
[20:53:29.247] iteration 13 : loss : 0.637052, loss_ce: 0.772746
[20:53:29.510] iteration 14 : loss : 0.461340, loss_ce: 0.552703
[20:53:29.773] iteration 15 : loss : 0.466231, loss_ce: 0.472308
[20:53:30.037] iteration 16 : loss : 0.371770, loss_ce: 0.277047
[20:53:30.300] iteration 17 : loss : 0.521530, loss_ce: 0.510318
[20:53:30.562] iteration 18 : loss : 0.394794, loss_ce: 0.281369
[20:53:30.824] iteration 19 : loss : 0.447066, loss_ce: 0.378069
[20:53:31.085] iteration 20 : loss : 0.510523, loss_ce: 0.490252
[20:53:52.042] Namespace(base_lr=0.01, batch_size=1, channels=4, deterministic=1, image_height=256, image_width=256, max_epochs=150, max_iterations=30000, model_path='/home/han/Documents/han/TNTUNet/model/', num_classes=2, save_interval=50, seed=42, testing_data_path=None, training_data_path='/home/han/Documents/han/TNTUNet/datasets/train/', validation_data_path=None)
[20:53:52.045] 200 iterations per epoch. 6000000 max iterations 
[20:53:52.343] iteration 1 : loss : 0.622453, loss_ce: 0.720597
[20:53:52.606] iteration 2 : loss : 0.406753, loss_ce: 0.359060
[20:53:52.868] iteration 3 : loss : 0.483752, loss_ce: 0.436378
[20:53:53.128] iteration 4 : loss : 0.443103, loss_ce: 0.361438
[20:53:53.393] iteration 5 : loss : 0.685712, loss_ce: 0.818877
[20:53:53.656] iteration 6 : loss : 0.601118, loss_ce: 0.662577
[20:53:53.925] iteration 7 : loss : 0.668690, loss_ce: 0.788942
[20:53:54.188] iteration 8 : loss : 0.676810, loss_ce: 0.802859
[20:53:54.452] iteration 9 : loss : 0.838662, loss_ce: 1.094503
[20:53:54.716] iteration 10 : loss : 0.517283, loss_ce: 0.500558
[20:53:54.980] iteration 11 : loss : 0.527787, loss_ce: 0.548979
[20:53:55.241] iteration 12 : loss : 0.447450, loss_ce: 0.569990
[20:53:55.502] iteration 13 : loss : 0.637052, loss_ce: 0.772746
[20:53:55.764] iteration 14 : loss : 0.461340, loss_ce: 0.552703
[20:53:56.027] iteration 15 : loss : 0.466231, loss_ce: 0.472308
[20:53:56.293] iteration 16 : loss : 0.371770, loss_ce: 0.277047
[20:53:56.557] iteration 17 : loss : 0.521530, loss_ce: 0.510318
[20:53:56.818] iteration 18 : loss : 0.394794, loss_ce: 0.281369
[20:53:57.080] iteration 19 : loss : 0.447066, loss_ce: 0.378069
[20:53:57.343] iteration 20 : loss : 0.510523, loss_ce: 0.490252
[21:04:46.849] Namespace(base_lr=0.01, batch_size=1, channels=4, deterministic=1, image_height=256, image_width=256, max_epochs=150, max_iterations=30000, model_path='/home/han/Documents/han/TNTUNet/model/', num_classes=2, save_interval=50, seed=42, testing_data_path=None, training_data_path='/home/han/Documents/han/TNTUNet/datasets/train/', validation_data_path=None)
[21:04:46.850] 200 iterations per epoch. 6000000 max iterations 
[21:04:47.153] iteration 1 : loss : 0.622453, loss_ce: 0.720597
[21:04:47.425] iteration 2 : loss : 0.406753, loss_ce: 0.359060
[21:04:47.683] iteration 3 : loss : 0.483752, loss_ce: 0.436378
[21:04:47.942] iteration 4 : loss : 0.443103, loss_ce: 0.361438
[21:04:48.204] iteration 5 : loss : 0.685712, loss_ce: 0.818877
[21:04:48.464] iteration 6 : loss : 0.601118, loss_ce: 0.662577
[21:04:48.727] iteration 7 : loss : 0.668690, loss_ce: 0.788942
[21:04:48.988] iteration 8 : loss : 0.676810, loss_ce: 0.802859
[21:04:49.252] iteration 9 : loss : 0.838662, loss_ce: 1.094503
[21:04:49.512] iteration 10 : loss : 0.517283, loss_ce: 0.500558
[21:04:49.778] iteration 11 : loss : 0.527787, loss_ce: 0.548979
[21:04:50.038] iteration 12 : loss : 0.447450, loss_ce: 0.569990
[21:04:50.297] iteration 13 : loss : 0.637052, loss_ce: 0.772746
[21:04:50.559] iteration 14 : loss : 0.461340, loss_ce: 0.552703
[21:04:50.822] iteration 15 : loss : 0.466231, loss_ce: 0.472308
[21:04:51.082] iteration 16 : loss : 0.371770, loss_ce: 0.277047
[21:04:51.342] iteration 17 : loss : 0.521530, loss_ce: 0.510318
[21:04:51.602] iteration 18 : loss : 0.394794, loss_ce: 0.281369
[21:04:51.861] iteration 19 : loss : 0.447066, loss_ce: 0.378069
[21:04:52.121] iteration 20 : loss : 0.510523, loss_ce: 0.490252
[21:05:17.738] Namespace(base_lr=0.01, batch_size=1, channels=4, deterministic=1, image_height=256, image_width=256, max_epochs=150, max_iterations=30000, model_path='/home/han/Documents/han/TNTUNet/model/', num_classes=2, save_interval=50, seed=42, testing_data_path=None, training_data_path='/home/han/Documents/han/TNTUNet/datasets/train/', validation_data_path=None)
[21:05:17.739] 200 iterations per epoch. 6000000 max iterations 
[21:05:18.017] iteration 1 : loss : 0.622453, loss_ce: 0.720597
[21:05:18.278] iteration 2 : loss : 0.406753, loss_ce: 0.359060
[21:05:18.550] iteration 3 : loss : 0.483752, loss_ce: 0.436378
[21:05:18.809] iteration 4 : loss : 0.443103, loss_ce: 0.361438
[21:05:19.073] iteration 5 : loss : 0.685712, loss_ce: 0.818877
[21:05:19.335] iteration 6 : loss : 0.601118, loss_ce: 0.662577
[21:05:19.595] iteration 7 : loss : 0.668690, loss_ce: 0.788942
[21:05:19.860] iteration 8 : loss : 0.676810, loss_ce: 0.802859
[21:05:20.123] iteration 9 : loss : 0.838662, loss_ce: 1.094503
[21:05:20.382] iteration 10 : loss : 0.517283, loss_ce: 0.500558
[21:05:20.646] iteration 11 : loss : 0.527787, loss_ce: 0.548979
[21:05:20.908] iteration 12 : loss : 0.447450, loss_ce: 0.569990
[21:05:21.167] iteration 13 : loss : 0.637052, loss_ce: 0.772746
[21:05:21.427] iteration 14 : loss : 0.461340, loss_ce: 0.552703
[21:05:21.690] iteration 15 : loss : 0.466231, loss_ce: 0.472308
[21:05:21.951] iteration 16 : loss : 0.371770, loss_ce: 0.277047
[21:05:22.212] iteration 17 : loss : 0.521530, loss_ce: 0.510318
[21:05:22.474] iteration 18 : loss : 0.394794, loss_ce: 0.281369
[21:05:22.735] iteration 19 : loss : 0.447066, loss_ce: 0.378069
[21:05:22.994] iteration 20 : loss : 0.510523, loss_ce: 0.490252
[21:06:43.638] Namespace(base_lr=0.01, batch_size=1, channels=4, deterministic=1, image_height=256, image_width=256, max_epochs=150, max_iterations=30000, model_path='/home/han/Documents/han/TNTUNet/model/', num_classes=2, save_interval=50, seed=42, testing_data_path=None, training_data_path='/home/han/Documents/han/TNTUNet/datasets/train/', validation_data_path=None)
[21:06:43.640] 200 iterations per epoch. 6000000 max iterations 
[21:06:43.930] iteration 1 : loss : 0.622453, loss_ce: 0.720597
[21:06:44.183] iteration 2 : loss : 0.406753, loss_ce: 0.359060
[21:06:44.438] iteration 3 : loss : 0.483752, loss_ce: 0.436378
[21:06:44.689] iteration 4 : loss : 0.443103, loss_ce: 0.361438
[21:06:44.945] iteration 5 : loss : 0.685712, loss_ce: 0.818877
[21:06:45.198] iteration 6 : loss : 0.601118, loss_ce: 0.662577
[21:06:45.453] iteration 7 : loss : 0.668690, loss_ce: 0.788942
[21:06:45.708] iteration 8 : loss : 0.676810, loss_ce: 0.802859
[21:06:45.963] iteration 9 : loss : 0.838662, loss_ce: 1.094503
[21:06:46.216] iteration 10 : loss : 0.517283, loss_ce: 0.500558
[21:06:46.473] iteration 11 : loss : 0.527787, loss_ce: 0.548979
[21:06:46.725] iteration 12 : loss : 0.447450, loss_ce: 0.569990
[21:06:46.977] iteration 13 : loss : 0.637052, loss_ce: 0.772746
[21:06:47.231] iteration 14 : loss : 0.461340, loss_ce: 0.552703
[21:06:47.485] iteration 15 : loss : 0.466231, loss_ce: 0.472308
[21:06:47.739] iteration 16 : loss : 0.371770, loss_ce: 0.277047
[21:06:47.992] iteration 17 : loss : 0.521530, loss_ce: 0.510318
[21:06:48.244] iteration 18 : loss : 0.394794, loss_ce: 0.281369
[21:06:48.495] iteration 19 : loss : 0.447066, loss_ce: 0.378069
[21:06:48.746] iteration 20 : loss : 0.510523, loss_ce: 0.490252
[21:06:49.046] iteration 21 : loss : 0.341241, loss_ce: 0.221335
[21:06:49.302] iteration 22 : loss : 0.306652, loss_ce: 0.184524
[21:06:49.551] iteration 23 : loss : 0.290642, loss_ce: 0.265088
[21:06:49.806] iteration 24 : loss : 0.368050, loss_ce: 0.316251
[21:06:50.059] iteration 25 : loss : 0.312733, loss_ce: 0.270625
[21:06:50.312] iteration 26 : loss : 0.305217, loss_ce: 0.264771
[21:06:50.569] iteration 27 : loss : 0.498815, loss_ce: 0.567627
[21:06:50.823] iteration 28 : loss : 0.339463, loss_ce: 0.409892
[21:06:51.076] iteration 29 : loss : 0.483531, loss_ce: 0.548180
[21:06:51.331] iteration 30 : loss : 0.394849, loss_ce: 0.481803
[21:06:51.586] iteration 31 : loss : 0.389790, loss_ce: 0.484921
[21:06:51.838] iteration 32 : loss : 0.346958, loss_ce: 0.389639
[21:06:52.088] iteration 33 : loss : 0.287163, loss_ce: 0.228367
[21:06:52.350] iteration 34 : loss : 0.508099, loss_ce: 0.492530
[21:06:52.602] iteration 35 : loss : 0.459583, loss_ce: 0.413213
[21:06:52.865] iteration 36 : loss : 0.442504, loss_ce: 0.371992
[21:06:53.145] iteration 37 : loss : 0.311940, loss_ce: 0.182201
[21:06:53.410] iteration 38 : loss : 0.352406, loss_ce: 0.213427
[21:06:53.661] iteration 39 : loss : 0.317218, loss_ce: 0.201588
[21:06:53.923] iteration 40 : loss : 0.634079, loss_ce: 0.734093
[21:06:54.239] iteration 41 : loss : 0.418006, loss_ce: 0.431144
[21:06:54.523] iteration 42 : loss : 0.420458, loss_ce: 0.509410
[21:06:54.779] iteration 43 : loss : 0.431775, loss_ce: 0.551535
[21:06:55.031] iteration 44 : loss : 0.532150, loss_ce: 0.691975
[21:06:55.280] iteration 45 : loss : 0.484747, loss_ce: 0.594923
[21:06:55.536] iteration 46 : loss : 0.405473, loss_ce: 0.497307
[21:06:55.788] iteration 47 : loss : 0.377499, loss_ce: 0.369974
[21:06:56.039] iteration 48 : loss : 0.321837, loss_ce: 0.254964
[21:06:56.292] iteration 49 : loss : 0.306432, loss_ce: 0.273235
[21:06:56.543] iteration 50 : loss : 0.238196, loss_ce: 0.170804
[21:06:56.794] iteration 51 : loss : 0.432104, loss_ce: 0.458044
[21:06:57.045] iteration 52 : loss : 0.258009, loss_ce: 0.223376
[21:06:57.310] iteration 53 : loss : 0.295300, loss_ce: 0.214163
[21:06:57.561] iteration 54 : loss : 0.249030, loss_ce: 0.203471
[21:06:57.814] iteration 55 : loss : 0.274995, loss_ce: 0.226857
[21:06:58.068] iteration 56 : loss : 0.349446, loss_ce: 0.286561
[21:06:58.320] iteration 57 : loss : 0.328710, loss_ce: 0.301779
[21:06:58.580] iteration 58 : loss : 0.310809, loss_ce: 0.308411
[21:06:58.859] iteration 59 : loss : 0.286772, loss_ce: 0.286584
[21:06:59.139] iteration 60 : loss : 0.326728, loss_ce: 0.321487
[21:06:59.446] iteration 61 : loss : 0.380646, loss_ce: 0.436364
[21:06:59.700] iteration 62 : loss : 0.426642, loss_ce: 0.500509
[21:06:59.953] iteration 63 : loss : 0.277344, loss_ce: 0.248831
[21:07:00.207] iteration 64 : loss : 0.268669, loss_ce: 0.259201
[21:07:00.465] iteration 65 : loss : 0.264192, loss_ce: 0.263965
[21:07:00.724] iteration 66 : loss : 0.371023, loss_ce: 0.425621
[21:07:00.984] iteration 67 : loss : 0.388428, loss_ce: 0.389583
[21:07:01.265] iteration 68 : loss : 0.278785, loss_ce: 0.275864
[21:07:01.547] iteration 69 : loss : 0.275661, loss_ce: 0.247953
[21:07:01.828] iteration 70 : loss : 0.300462, loss_ce: 0.258440
[21:07:02.114] iteration 71 : loss : 0.282894, loss_ce: 0.275976
[21:07:02.370] iteration 72 : loss : 0.444943, loss_ce: 0.522411
[21:07:02.632] iteration 73 : loss : 0.317545, loss_ce: 0.347620
[21:07:02.918] iteration 74 : loss : 0.343742, loss_ce: 0.421820
[21:07:03.213] iteration 75 : loss : 0.313288, loss_ce: 0.379296
[21:07:03.510] iteration 76 : loss : 0.312126, loss_ce: 0.369856
[21:07:03.794] iteration 77 : loss : 0.350365, loss_ce: 0.330877
[21:07:04.076] iteration 78 : loss : 0.308119, loss_ce: 0.373090
[21:07:04.362] iteration 79 : loss : 0.338453, loss_ce: 0.402183
[21:07:04.619] iteration 80 : loss : 0.290355, loss_ce: 0.308208
[21:07:04.910] iteration 81 : loss : 0.266890, loss_ce: 0.235075
[21:07:05.168] iteration 82 : loss : 0.310609, loss_ce: 0.290601
[21:07:05.422] iteration 83 : loss : 0.209826, loss_ce: 0.190683
[21:07:05.679] iteration 84 : loss : 0.276068, loss_ce: 0.241208
[21:07:05.935] iteration 85 : loss : 0.292256, loss_ce: 0.249737
[21:07:06.189] iteration 86 : loss : 0.369950, loss_ce: 0.356336
[21:07:06.440] iteration 87 : loss : 0.278617, loss_ce: 0.268559
[21:07:06.695] iteration 88 : loss : 0.236178, loss_ce: 0.223571
[21:07:06.951] iteration 89 : loss : 0.569790, loss_ce: 0.753063
[21:07:07.202] iteration 90 : loss : 0.278936, loss_ce: 0.323935
[21:07:07.453] iteration 91 : loss : 0.291798, loss_ce: 0.319011
[21:07:07.704] iteration 92 : loss : 0.314384, loss_ce: 0.299324
[21:07:07.963] iteration 93 : loss : 0.315077, loss_ce: 0.372646
[21:07:08.217] iteration 94 : loss : 0.279119, loss_ce: 0.337238
[21:07:08.469] iteration 95 : loss : 0.271372, loss_ce: 0.267868
[21:07:08.721] iteration 96 : loss : 0.295229, loss_ce: 0.247942
[21:07:08.976] iteration 97 : loss : 0.464864, loss_ce: 0.541925
[21:07:09.228] iteration 98 : loss : 0.273900, loss_ce: 0.242751
[21:07:09.479] iteration 99 : loss : 0.244146, loss_ce: 0.190380
[21:07:09.730] iteration 100 : loss : 0.217820, loss_ce: 0.179441
[21:07:10.019] iteration 101 : loss : 0.299506, loss_ce: 0.232648
[21:07:10.274] iteration 102 : loss : 0.327554, loss_ce: 0.345657
[21:07:10.562] iteration 103 : loss : 0.329955, loss_ce: 0.215916
[21:07:10.827] iteration 104 : loss : 0.288762, loss_ce: 0.261564
[21:07:11.082] iteration 105 : loss : 0.402118, loss_ce: 0.441726
[21:07:11.335] iteration 106 : loss : 0.296600, loss_ce: 0.284311
[21:07:11.586] iteration 107 : loss : 0.281559, loss_ce: 0.274840
[21:07:11.852] iteration 108 : loss : 0.270717, loss_ce: 0.297689
[21:07:12.102] iteration 109 : loss : 0.318683, loss_ce: 0.326640
[21:07:12.361] iteration 110 : loss : 0.424862, loss_ce: 0.540116
[21:07:12.628] iteration 111 : loss : 0.293317, loss_ce: 0.332164
[21:07:12.880] iteration 112 : loss : 0.253105, loss_ce: 0.294888
[21:07:13.139] iteration 113 : loss : 0.271112, loss_ce: 0.255951
[21:07:13.392] iteration 114 : loss : 0.273986, loss_ce: 0.288134
[21:07:13.646] iteration 115 : loss : 0.249630, loss_ce: 0.220568
[21:07:13.899] iteration 116 : loss : 0.246807, loss_ce: 0.257679
[21:07:14.158] iteration 117 : loss : 0.279963, loss_ce: 0.292883
[21:07:14.417] iteration 118 : loss : 0.455653, loss_ce: 0.523855
[21:07:14.672] iteration 119 : loss : 0.259963, loss_ce: 0.193964
[21:07:14.927] iteration 120 : loss : 0.278036, loss_ce: 0.286014
[21:07:15.236] iteration 121 : loss : 0.335212, loss_ce: 0.397653
[21:07:15.490] iteration 122 : loss : 0.264144, loss_ce: 0.307365
[21:07:15.749] iteration 123 : loss : 0.265458, loss_ce: 0.300279
[21:07:16.016] iteration 124 : loss : 0.308497, loss_ce: 0.279688
[21:07:16.269] iteration 125 : loss : 0.261324, loss_ce: 0.293884
[21:07:16.520] iteration 126 : loss : 0.287785, loss_ce: 0.258137
[21:07:16.773] iteration 127 : loss : 0.257801, loss_ce: 0.281646
[21:07:17.026] iteration 128 : loss : 0.241400, loss_ce: 0.262309
[21:07:17.283] iteration 129 : loss : 0.495271, loss_ce: 0.592617
[21:07:17.535] iteration 130 : loss : 0.243352, loss_ce: 0.274229
[21:07:17.805] iteration 131 : loss : 0.220101, loss_ce: 0.223783
[21:07:18.064] iteration 132 : loss : 0.264358, loss_ce: 0.248912
[21:07:18.317] iteration 133 : loss : 0.248026, loss_ce: 0.219848
[21:07:18.571] iteration 134 : loss : 0.270083, loss_ce: 0.237587
[21:07:18.827] iteration 135 : loss : 0.261231, loss_ce: 0.267819
[21:07:19.081] iteration 136 : loss : 0.217826, loss_ce: 0.151948
[21:07:19.337] iteration 137 : loss : 0.236528, loss_ce: 0.203678
[21:07:19.597] iteration 138 : loss : 0.445446, loss_ce: 0.514669
[21:07:19.851] iteration 139 : loss : 0.243785, loss_ce: 0.216430
[21:07:20.109] iteration 140 : loss : 0.494910, loss_ce: 0.631397
[21:07:20.405] iteration 141 : loss : 0.245111, loss_ce: 0.290549
[21:07:20.657] iteration 142 : loss : 0.304555, loss_ce: 0.329431
[21:07:20.914] iteration 143 : loss : 0.356602, loss_ce: 0.407835
[21:07:21.170] iteration 144 : loss : 0.372165, loss_ce: 0.371935
[21:07:21.427] iteration 145 : loss : 0.247597, loss_ce: 0.290201
[21:07:21.679] iteration 146 : loss : 0.378004, loss_ce: 0.439487
[21:07:21.937] iteration 147 : loss : 0.283669, loss_ce: 0.323103
[21:07:22.190] iteration 148 : loss : 0.272463, loss_ce: 0.243043
[21:07:22.445] iteration 149 : loss : 0.314396, loss_ce: 0.342837
[21:07:22.704] iteration 150 : loss : 0.358130, loss_ce: 0.331992
[21:07:22.956] iteration 151 : loss : 0.233020, loss_ce: 0.200672
[21:07:23.209] iteration 152 : loss : 0.250801, loss_ce: 0.203769
[21:07:23.463] iteration 153 : loss : 0.359859, loss_ce: 0.431128
[21:07:23.721] iteration 154 : loss : 0.359151, loss_ce: 0.401092
[21:07:23.974] iteration 155 : loss : 0.276934, loss_ce: 0.315423
[21:07:24.263] iteration 156 : loss : 0.340340, loss_ce: 0.437991
[21:07:24.546] iteration 157 : loss : 0.256253, loss_ce: 0.306246
[21:07:24.832] iteration 158 : loss : 0.274998, loss_ce: 0.246231
[21:07:25.092] iteration 159 : loss : 0.300969, loss_ce: 0.392180
[21:07:25.354] iteration 160 : loss : 0.298885, loss_ce: 0.298898
[21:07:25.654] iteration 161 : loss : 0.316988, loss_ce: 0.391060
[21:07:25.920] iteration 162 : loss : 0.250256, loss_ce: 0.256509
[21:07:26.176] iteration 163 : loss : 0.282257, loss_ce: 0.269613
[21:07:26.428] iteration 164 : loss : 0.220510, loss_ce: 0.207002
[21:07:26.687] iteration 165 : loss : 0.307623, loss_ce: 0.293317
[21:07:26.939] iteration 166 : loss : 0.225982, loss_ce: 0.181719
[21:07:27.193] iteration 167 : loss : 0.229404, loss_ce: 0.175555
[21:07:27.456] iteration 168 : loss : 0.261785, loss_ce: 0.225572
[21:07:27.710] iteration 169 : loss : 0.188768, loss_ce: 0.152205
[21:07:27.964] iteration 170 : loss : 0.185612, loss_ce: 0.122562
[21:07:28.218] iteration 171 : loss : 0.218424, loss_ce: 0.168944
[21:07:28.477] iteration 172 : loss : 0.313441, loss_ce: 0.290764
[21:07:28.748] iteration 173 : loss : 0.212405, loss_ce: 0.166862
[21:07:29.034] iteration 174 : loss : 0.463157, loss_ce: 0.517943
[21:07:29.288] iteration 175 : loss : 0.285493, loss_ce: 0.270329
[21:07:29.540] iteration 176 : loss : 0.256809, loss_ce: 0.260537
[21:07:29.792] iteration 177 : loss : 0.244628, loss_ce: 0.257492
[21:07:30.049] iteration 178 : loss : 0.412712, loss_ce: 0.530690
[21:07:30.301] iteration 179 : loss : 0.278888, loss_ce: 0.275147
[21:07:30.553] iteration 180 : loss : 0.297339, loss_ce: 0.342043
[21:07:30.853] iteration 181 : loss : 0.338052, loss_ce: 0.337523
[21:07:31.111] iteration 182 : loss : 0.261324, loss_ce: 0.236769
[21:07:31.364] iteration 183 : loss : 0.263751, loss_ce: 0.256357
[21:07:31.620] iteration 184 : loss : 0.246631, loss_ce: 0.260818
[21:07:31.887] iteration 185 : loss : 0.240019, loss_ce: 0.219527
[21:07:32.140] iteration 186 : loss : 0.219335, loss_ce: 0.166617
[21:07:32.394] iteration 187 : loss : 0.429533, loss_ce: 0.459942
[21:07:32.648] iteration 188 : loss : 0.340602, loss_ce: 0.272539
[21:07:32.902] iteration 189 : loss : 0.392456, loss_ce: 0.407142
[21:07:33.155] iteration 190 : loss : 0.241170, loss_ce: 0.177704
[21:07:33.409] iteration 191 : loss : 0.282465, loss_ce: 0.249551
[21:07:33.663] iteration 192 : loss : 0.223437, loss_ce: 0.178273
[21:07:33.917] iteration 193 : loss : 0.300628, loss_ce: 0.354741
[21:07:34.169] iteration 194 : loss : 0.278585, loss_ce: 0.286742
[21:07:34.422] iteration 195 : loss : 0.234284, loss_ce: 0.246124
[21:07:34.673] iteration 196 : loss : 0.261311, loss_ce: 0.271079
[21:07:34.926] iteration 197 : loss : 0.283745, loss_ce: 0.230439
[21:07:35.179] iteration 198 : loss : 0.274009, loss_ce: 0.323789
[21:07:35.435] iteration 199 : loss : 0.250505, loss_ce: 0.200692
[21:07:35.690] iteration 200 : loss : 0.280528, loss_ce: 0.265372
[21:07:35.996] iteration 201 : loss : 0.237596, loss_ce: 0.207316
[21:07:36.253] iteration 202 : loss : 0.275565, loss_ce: 0.252462
[21:07:36.515] iteration 203 : loss : 0.417728, loss_ce: 0.518815
[21:07:36.769] iteration 204 : loss : 0.365081, loss_ce: 0.436264
[21:07:37.028] iteration 205 : loss : 0.263699, loss_ce: 0.268239
[21:07:37.283] iteration 206 : loss : 0.269768, loss_ce: 0.284476
[21:07:37.536] iteration 207 : loss : 0.259575, loss_ce: 0.304725
[21:07:37.792] iteration 208 : loss : 0.392956, loss_ce: 0.529508
[21:07:38.044] iteration 209 : loss : 0.240474, loss_ce: 0.292045
[21:07:38.298] iteration 210 : loss : 0.250211, loss_ce: 0.228388
[21:07:38.553] iteration 211 : loss : 0.254065, loss_ce: 0.312871
[21:07:38.809] iteration 212 : loss : 0.255715, loss_ce: 0.240424
[21:07:39.066] iteration 213 : loss : 0.240055, loss_ce: 0.223165
[21:07:39.322] iteration 214 : loss : 0.205445, loss_ce: 0.169763
[21:07:39.582] iteration 215 : loss : 0.214550, loss_ce: 0.188035
[21:07:39.853] iteration 216 : loss : 0.212543, loss_ce: 0.145401
[21:07:40.127] iteration 217 : loss : 0.294521, loss_ce: 0.241720
[21:07:40.391] iteration 218 : loss : 0.216745, loss_ce: 0.177016
[21:07:40.651] iteration 219 : loss : 0.389801, loss_ce: 0.404618
[21:07:40.939] iteration 220 : loss : 0.422534, loss_ce: 0.485879
[21:07:41.282] iteration 221 : loss : 0.311348, loss_ce: 0.304280
[21:07:41.572] iteration 222 : loss : 0.249390, loss_ce: 0.228485
[21:07:41.825] iteration 223 : loss : 0.301369, loss_ce: 0.244509
[21:07:42.077] iteration 224 : loss : 0.302900, loss_ce: 0.269020
[21:07:42.335] iteration 225 : loss : 0.291158, loss_ce: 0.346744
[21:07:42.590] iteration 226 : loss : 0.292397, loss_ce: 0.223988
[21:07:42.847] iteration 227 : loss : 0.198275, loss_ce: 0.179760
[21:07:43.106] iteration 228 : loss : 0.442539, loss_ce: 0.540445
[21:07:43.371] iteration 229 : loss : 0.454580, loss_ce: 0.565582
[21:07:43.630] iteration 230 : loss : 0.366723, loss_ce: 0.457731
[21:07:43.883] iteration 231 : loss : 0.321432, loss_ce: 0.285592
[21:07:44.140] iteration 232 : loss : 0.313427, loss_ce: 0.404033
[21:07:44.394] iteration 233 : loss : 0.301243, loss_ce: 0.373973
[21:07:44.649] iteration 234 : loss : 0.384381, loss_ce: 0.383441
[21:07:44.905] iteration 235 : loss : 0.324106, loss_ce: 0.369031
[21:07:45.157] iteration 236 : loss : 0.261392, loss_ce: 0.227700
[21:07:45.410] iteration 237 : loss : 0.259948, loss_ce: 0.247511
[21:07:45.663] iteration 238 : loss : 0.245684, loss_ce: 0.270505
[21:07:45.917] iteration 239 : loss : 0.211141, loss_ce: 0.183123
[21:07:46.169] iteration 240 : loss : 0.272764, loss_ce: 0.286718
[21:07:46.463] iteration 241 : loss : 0.647149, loss_ce: 0.895587
[21:07:46.717] iteration 242 : loss : 0.274198, loss_ce: 0.295701
[21:07:46.969] iteration 243 : loss : 0.264163, loss_ce: 0.255970
[21:07:47.222] iteration 244 : loss : 0.242530, loss_ce: 0.286696
[21:07:47.482] iteration 245 : loss : 0.525223, loss_ce: 0.683664
[21:07:47.739] iteration 246 : loss : 0.268026, loss_ce: 0.287905
[21:07:48.003] iteration 247 : loss : 0.477743, loss_ce: 0.671346
[21:07:48.261] iteration 248 : loss : 0.244064, loss_ce: 0.253351
[21:07:48.518] iteration 249 : loss : 0.337215, loss_ce: 0.395629
[21:07:48.780] iteration 250 : loss : 0.316138, loss_ce: 0.388781
[21:07:49.035] iteration 251 : loss : 0.344764, loss_ce: 0.343906
[21:07:49.291] iteration 252 : loss : 0.320247, loss_ce: 0.296707
[21:07:49.545] iteration 253 : loss : 0.255395, loss_ce: 0.258046
[21:07:49.805] iteration 254 : loss : 0.233042, loss_ce: 0.221255
[21:07:50.062] iteration 255 : loss : 0.253513, loss_ce: 0.230206
[21:07:50.318] iteration 256 : loss : 0.252072, loss_ce: 0.256942
[21:07:50.574] iteration 257 : loss : 0.339033, loss_ce: 0.358788
[21:07:50.832] iteration 258 : loss : 0.265886, loss_ce: 0.270976
[21:07:51.087] iteration 259 : loss : 0.231063, loss_ce: 0.244287
[21:07:51.343] iteration 260 : loss : 0.325932, loss_ce: 0.293626
[21:07:51.648] iteration 261 : loss : 0.249686, loss_ce: 0.267105
[21:07:51.905] iteration 262 : loss : 0.344315, loss_ce: 0.368246
[21:07:52.161] iteration 263 : loss : 0.299326, loss_ce: 0.338930
[21:07:52.417] iteration 264 : loss : 0.278106, loss_ce: 0.266445
[21:07:52.680] iteration 265 : loss : 0.262614, loss_ce: 0.321305
[21:07:52.938] iteration 266 : loss : 0.252991, loss_ce: 0.260193
[21:07:53.194] iteration 267 : loss : 0.352447, loss_ce: 0.422606
[21:07:53.457] iteration 268 : loss : 0.272635, loss_ce: 0.272033
[21:07:53.713] iteration 269 : loss : 0.268651, loss_ce: 0.331306
[21:07:53.968] iteration 270 : loss : 0.273503, loss_ce: 0.261144
[21:07:54.225] iteration 271 : loss : 0.243815, loss_ce: 0.270061
[21:07:54.480] iteration 272 : loss : 0.271523, loss_ce: 0.299893
[21:07:54.733] iteration 273 : loss : 0.256639, loss_ce: 0.218126
[21:07:54.989] iteration 274 : loss : 0.294207, loss_ce: 0.299151
[21:07:55.246] iteration 275 : loss : 0.254009, loss_ce: 0.281000
[21:07:55.499] iteration 276 : loss : 0.241567, loss_ce: 0.197546
[21:07:55.753] iteration 277 : loss : 0.202292, loss_ce: 0.165044
[21:07:56.008] iteration 278 : loss : 0.247734, loss_ce: 0.172268
[21:07:56.265] iteration 279 : loss : 0.278334, loss_ce: 0.303992
[21:07:56.519] iteration 280 : loss : 0.252280, loss_ce: 0.197218
[21:07:56.842] iteration 281 : loss : 0.252541, loss_ce: 0.185132
[21:07:57.111] iteration 282 : loss : 0.218399, loss_ce: 0.159222
[21:07:57.386] iteration 283 : loss : 0.225064, loss_ce: 0.238028
[21:07:57.653] iteration 284 : loss : 0.290192, loss_ce: 0.335682
[21:07:57.911] iteration 285 : loss : 0.311233, loss_ce: 0.372927
[21:07:58.169] iteration 286 : loss : 0.284859, loss_ce: 0.331168
[21:07:58.425] iteration 287 : loss : 0.229421, loss_ce: 0.255737
[21:07:58.681] iteration 288 : loss : 0.227113, loss_ce: 0.203339
[21:07:58.936] iteration 289 : loss : 0.226651, loss_ce: 0.216252
[21:07:59.195] iteration 290 : loss : 0.253957, loss_ce: 0.246123
[21:07:59.453] iteration 291 : loss : 0.263267, loss_ce: 0.256587
[21:07:59.713] iteration 292 : loss : 0.249818, loss_ce: 0.252706
[21:07:59.967] iteration 293 : loss : 0.341919, loss_ce: 0.407583
[21:08:00.222] iteration 294 : loss : 0.204675, loss_ce: 0.181676
[21:08:00.475] iteration 295 : loss : 0.229916, loss_ce: 0.241381
[21:08:00.730] iteration 296 : loss : 0.295884, loss_ce: 0.242497
[21:08:00.984] iteration 297 : loss : 0.218990, loss_ce: 0.241884
[21:08:01.241] iteration 298 : loss : 0.208982, loss_ce: 0.196833
[21:08:01.496] iteration 299 : loss : 0.395711, loss_ce: 0.506265
[21:08:01.753] iteration 300 : loss : 0.290329, loss_ce: 0.334457
[21:08:02.065] iteration 301 : loss : 0.249998, loss_ce: 0.224362
[21:08:02.320] iteration 302 : loss : 0.242639, loss_ce: 0.210821
[21:08:02.577] iteration 303 : loss : 0.258838, loss_ce: 0.287150
[21:08:02.833] iteration 304 : loss : 0.268373, loss_ce: 0.250539
[21:08:03.095] iteration 305 : loss : 0.292809, loss_ce: 0.365041
[21:08:03.364] iteration 306 : loss : 0.283277, loss_ce: 0.353150
[21:08:03.635] iteration 307 : loss : 0.274652, loss_ce: 0.264018
[21:08:03.902] iteration 308 : loss : 0.240853, loss_ce: 0.285792
[21:08:04.171] iteration 309 : loss : 0.281298, loss_ce: 0.307996
[21:08:04.458] iteration 310 : loss : 0.300266, loss_ce: 0.303391
[21:08:04.758] iteration 311 : loss : 0.226881, loss_ce: 0.230874
[21:08:05.033] iteration 312 : loss : 0.250756, loss_ce: 0.223985
[21:08:05.307] iteration 313 : loss : 0.228447, loss_ce: 0.198806
[21:08:05.584] iteration 314 : loss : 0.246377, loss_ce: 0.265825
[21:08:05.860] iteration 315 : loss : 0.211285, loss_ce: 0.179843
[21:08:06.150] iteration 316 : loss : 0.349863, loss_ce: 0.385321
[21:08:06.421] iteration 317 : loss : 0.279601, loss_ce: 0.309699
[21:08:06.696] iteration 318 : loss : 0.245714, loss_ce: 0.245837
[21:08:06.986] iteration 319 : loss : 0.448109, loss_ce: 0.493861
[21:08:07.272] iteration 320 : loss : 0.339899, loss_ce: 0.396179
[21:08:07.600] iteration 321 : loss : 0.286097, loss_ce: 0.255011
[21:08:07.865] iteration 322 : loss : 0.236566, loss_ce: 0.289943
[21:08:08.121] iteration 323 : loss : 0.240751, loss_ce: 0.291720
[21:08:08.406] iteration 324 : loss : 0.220953, loss_ce: 0.235002
[21:08:08.690] iteration 325 : loss : 0.258288, loss_ce: 0.273552
[21:08:08.959] iteration 326 : loss : 0.226296, loss_ce: 0.259601
[21:08:09.244] iteration 327 : loss : 0.217173, loss_ce: 0.256891
[21:08:09.502] iteration 328 : loss : 0.229137, loss_ce: 0.259104
[21:08:09.754] iteration 329 : loss : 0.224408, loss_ce: 0.210532
[21:08:10.006] iteration 330 : loss : 0.250201, loss_ce: 0.235245
[21:08:10.258] iteration 331 : loss : 0.231612, loss_ce: 0.191081
[21:08:10.512] iteration 332 : loss : 0.260854, loss_ce: 0.245836
[21:08:10.764] iteration 333 : loss : 0.210176, loss_ce: 0.213030
[21:08:11.021] iteration 334 : loss : 0.471844, loss_ce: 0.531733
[21:08:11.274] iteration 335 : loss : 0.221220, loss_ce: 0.222294
[21:08:11.528] iteration 336 : loss : 0.197880, loss_ce: 0.174534
[21:08:11.783] iteration 337 : loss : 0.257006, loss_ce: 0.226735
[21:08:12.037] iteration 338 : loss : 0.243113, loss_ce: 0.213741
[21:08:12.290] iteration 339 : loss : 0.190596, loss_ce: 0.192912
[21:08:12.542] iteration 340 : loss : 0.211518, loss_ce: 0.189338
[21:08:12.838] iteration 341 : loss : 0.306349, loss_ce: 0.391241
[21:08:13.109] iteration 342 : loss : 0.221706, loss_ce: 0.242438
[21:08:13.380] iteration 343 : loss : 0.233909, loss_ce: 0.250357
[21:08:13.635] iteration 344 : loss : 0.248636, loss_ce: 0.295827
[21:08:13.922] iteration 345 : loss : 0.261625, loss_ce: 0.239077
[21:08:14.181] iteration 346 : loss : 0.229332, loss_ce: 0.255857
[21:08:14.448] iteration 347 : loss : 0.268862, loss_ce: 0.223880
[21:08:14.731] iteration 348 : loss : 0.259167, loss_ce: 0.217145
[21:08:14.992] iteration 349 : loss : 0.324302, loss_ce: 0.402878
[21:08:15.244] iteration 350 : loss : 0.194333, loss_ce: 0.172640
[21:08:15.498] iteration 351 : loss : 0.223593, loss_ce: 0.194619
[21:08:15.777] iteration 352 : loss : 0.284764, loss_ce: 0.225268
[21:08:16.038] iteration 353 : loss : 0.232536, loss_ce: 0.203024
[21:08:16.291] iteration 354 : loss : 0.190216, loss_ce: 0.138749
[21:08:16.544] iteration 355 : loss : 0.283723, loss_ce: 0.257793
[21:08:16.798] iteration 356 : loss : 0.318396, loss_ce: 0.309603
[21:08:17.050] iteration 357 : loss : 0.234158, loss_ce: 0.218796
[21:08:17.329] iteration 358 : loss : 0.311491, loss_ce: 0.330777
[21:08:17.612] iteration 359 : loss : 0.237368, loss_ce: 0.270910
[21:08:17.893] iteration 360 : loss : 0.244924, loss_ce: 0.264878
[21:08:18.200] iteration 361 : loss : 0.242786, loss_ce: 0.242202
[21:08:18.477] iteration 362 : loss : 0.247064, loss_ce: 0.295271
[21:08:18.759] iteration 363 : loss : 0.368119, loss_ce: 0.432506
[21:08:19.021] iteration 364 : loss : 0.248244, loss_ce: 0.227527
[21:08:19.274] iteration 365 : loss : 0.227182, loss_ce: 0.253313
[21:08:19.550] iteration 366 : loss : 0.259970, loss_ce: 0.314593
[21:08:19.812] iteration 367 : loss : 0.255584, loss_ce: 0.276909
[21:08:20.076] iteration 368 : loss : 0.463072, loss_ce: 0.572844
[21:08:20.338] iteration 369 : loss : 0.432631, loss_ce: 0.569038
[21:08:20.597] iteration 370 : loss : 0.216839, loss_ce: 0.235520
[21:08:20.878] iteration 371 : loss : 0.222091, loss_ce: 0.275886
[21:08:21.143] iteration 372 : loss : 0.232084, loss_ce: 0.283196
[21:08:21.397] iteration 373 : loss : 0.237928, loss_ce: 0.207475
[21:08:21.652] iteration 374 : loss : 0.253115, loss_ce: 0.252567
[21:08:21.907] iteration 375 : loss : 0.227606, loss_ce: 0.259664
[21:08:22.188] iteration 376 : loss : 0.225162, loss_ce: 0.247604
[21:08:22.450] iteration 377 : loss : 0.179551, loss_ce: 0.131994
[21:08:22.707] iteration 378 : loss : 0.340888, loss_ce: 0.360822
[21:08:22.967] iteration 379 : loss : 0.393027, loss_ce: 0.453163
[21:08:23.254] iteration 380 : loss : 0.360329, loss_ce: 0.385935
[21:08:23.545] iteration 381 : loss : 0.194187, loss_ce: 0.147853
[21:08:23.805] iteration 382 : loss : 0.262500, loss_ce: 0.270555
[21:08:24.086] iteration 383 : loss : 0.254013, loss_ce: 0.199449
[21:08:24.344] iteration 384 : loss : 0.238763, loss_ce: 0.224131
[21:08:24.631] iteration 385 : loss : 0.282500, loss_ce: 0.297237
[21:08:24.887] iteration 386 : loss : 0.247349, loss_ce: 0.244707
[21:08:25.147] iteration 387 : loss : 0.394655, loss_ce: 0.468599
[21:08:25.431] iteration 388 : loss : 0.239894, loss_ce: 0.255975
[21:08:25.688] iteration 389 : loss : 0.245392, loss_ce: 0.262598
[21:08:25.947] iteration 390 : loss : 0.270366, loss_ce: 0.314318
[21:08:26.217] iteration 391 : loss : 0.266044, loss_ce: 0.257362
[21:08:26.500] iteration 392 : loss : 0.270269, loss_ce: 0.284206
[21:08:26.759] iteration 393 : loss : 0.242364, loss_ce: 0.256006
[21:08:27.018] iteration 394 : loss : 0.237061, loss_ce: 0.241454
[21:08:27.273] iteration 395 : loss : 0.244348, loss_ce: 0.214937
[21:08:27.560] iteration 396 : loss : 0.313930, loss_ce: 0.401660
[21:08:27.826] iteration 397 : loss : 0.205244, loss_ce: 0.170298
[21:08:28.109] iteration 398 : loss : 0.230131, loss_ce: 0.217726
[21:08:28.387] iteration 399 : loss : 0.242870, loss_ce: 0.285474
[21:08:28.669] iteration 400 : loss : 0.286857, loss_ce: 0.274323
[21:08:28.976] iteration 401 : loss : 0.319696, loss_ce: 0.368223
[21:08:29.230] iteration 402 : loss : 0.278852, loss_ce: 0.228700
[21:08:29.507] iteration 403 : loss : 0.231406, loss_ce: 0.222434
[21:08:29.772] iteration 404 : loss : 0.241106, loss_ce: 0.195782
[21:08:30.059] iteration 405 : loss : 0.299056, loss_ce: 0.363329
[21:08:30.323] iteration 406 : loss : 0.348387, loss_ce: 0.438605
[21:08:30.583] iteration 407 : loss : 0.419606, loss_ce: 0.518306
[21:08:30.835] iteration 408 : loss : 0.236193, loss_ce: 0.217958
[21:08:31.113] iteration 409 : loss : 0.271068, loss_ce: 0.275152
[21:08:31.399] iteration 410 : loss : 0.234163, loss_ce: 0.284532
[21:08:31.655] iteration 411 : loss : 0.231766, loss_ce: 0.271584
[21:08:31.933] iteration 412 : loss : 0.281673, loss_ce: 0.338548
[21:08:32.220] iteration 413 : loss : 0.246542, loss_ce: 0.302116
[21:08:32.479] iteration 414 : loss : 0.349975, loss_ce: 0.453265
[21:08:32.733] iteration 415 : loss : 0.210910, loss_ce: 0.235998
[21:08:32.990] iteration 416 : loss : 0.193325, loss_ce: 0.208109
[21:08:33.279] iteration 417 : loss : 0.269894, loss_ce: 0.320043
[21:08:33.567] iteration 418 : loss : 0.318321, loss_ce: 0.353563
[21:08:33.857] iteration 419 : loss : 0.276499, loss_ce: 0.228060
[21:08:34.144] iteration 420 : loss : 0.223952, loss_ce: 0.220386
[21:08:34.469] iteration 421 : loss : 0.232697, loss_ce: 0.275308
[21:08:34.729] iteration 422 : loss : 0.249535, loss_ce: 0.289294
[21:08:34.985] iteration 423 : loss : 0.206506, loss_ce: 0.202924
[21:08:35.241] iteration 424 : loss : 0.220137, loss_ce: 0.199809
[21:08:35.499] iteration 425 : loss : 0.213495, loss_ce: 0.195294
[21:08:35.755] iteration 426 : loss : 0.214805, loss_ce: 0.184509
[21:08:36.010] iteration 427 : loss : 0.230858, loss_ce: 0.242087
[21:08:36.270] iteration 428 : loss : 0.500766, loss_ce: 0.647132
[21:08:36.525] iteration 429 : loss : 0.236996, loss_ce: 0.247897
[21:08:36.785] iteration 430 : loss : 0.434369, loss_ce: 0.541112
[21:08:37.041] iteration 431 : loss : 0.199588, loss_ce: 0.220341
[21:08:37.297] iteration 432 : loss : 0.216007, loss_ce: 0.234072
[21:08:37.554] iteration 433 : loss : 0.281049, loss_ce: 0.303063
[21:08:37.812] iteration 434 : loss : 0.291310, loss_ce: 0.294771
[21:08:38.068] iteration 435 : loss : 0.222505, loss_ce: 0.256733
[21:08:38.324] iteration 436 : loss : 0.216565, loss_ce: 0.238576
[21:08:38.581] iteration 437 : loss : 0.246996, loss_ce: 0.285946
[21:08:38.837] iteration 438 : loss : 0.212262, loss_ce: 0.235086
[21:08:39.097] iteration 439 : loss : 0.298416, loss_ce: 0.377512
[21:08:39.353] iteration 440 : loss : 0.266820, loss_ce: 0.244481
[21:08:39.654] iteration 441 : loss : 0.196285, loss_ce: 0.211667
[21:08:39.909] iteration 442 : loss : 0.201364, loss_ce: 0.211819
[21:08:40.164] iteration 443 : loss : 0.205008, loss_ce: 0.223733
[21:08:40.419] iteration 444 : loss : 0.197161, loss_ce: 0.182690
[21:08:40.676] iteration 445 : loss : 0.303660, loss_ce: 0.335756
[21:08:40.932] iteration 446 : loss : 0.317528, loss_ce: 0.326851
[21:08:41.190] iteration 447 : loss : 0.222549, loss_ce: 0.268166
[21:08:41.448] iteration 448 : loss : 0.364180, loss_ce: 0.443402
[21:08:41.703] iteration 449 : loss : 0.232156, loss_ce: 0.232770
[21:08:41.960] iteration 450 : loss : 0.256663, loss_ce: 0.301622
[21:08:42.215] iteration 451 : loss : 0.276672, loss_ce: 0.304478
[21:08:42.495] iteration 452 : loss : 0.270286, loss_ce: 0.282458
[21:08:42.766] iteration 453 : loss : 0.368283, loss_ce: 0.495095
[21:08:43.051] iteration 454 : loss : 0.280168, loss_ce: 0.261212
[21:08:43.325] iteration 455 : loss : 0.258196, loss_ce: 0.305120
[21:08:43.597] iteration 456 : loss : 0.249956, loss_ce: 0.258443
[21:08:43.854] iteration 457 : loss : 0.225140, loss_ce: 0.266966
[21:08:44.109] iteration 458 : loss : 0.205054, loss_ce: 0.228240
[21:08:44.391] iteration 459 : loss : 0.167934, loss_ce: 0.169454
[21:08:44.650] iteration 460 : loss : 0.227934, loss_ce: 0.209876
[21:08:44.956] iteration 461 : loss : 0.221353, loss_ce: 0.239110
[21:08:45.209] iteration 462 : loss : 0.207319, loss_ce: 0.177836
[21:08:45.466] iteration 463 : loss : 0.243232, loss_ce: 0.207232
[21:08:45.720] iteration 464 : loss : 0.208552, loss_ce: 0.169777
[21:08:45.976] iteration 465 : loss : 0.230482, loss_ce: 0.217904
[21:08:46.234] iteration 466 : loss : 0.214695, loss_ce: 0.197902
[21:08:46.488] iteration 467 : loss : 0.233552, loss_ce: 0.186496
[21:08:46.745] iteration 468 : loss : 0.225732, loss_ce: 0.261023
[21:08:47.001] iteration 469 : loss : 0.217816, loss_ce: 0.223775
[21:08:47.257] iteration 470 : loss : 0.205526, loss_ce: 0.226617
[21:08:47.544] iteration 471 : loss : 0.218762, loss_ce: 0.204446
[21:08:47.836] iteration 472 : loss : 0.367806, loss_ce: 0.406188
[21:08:48.092] iteration 473 : loss : 0.230053, loss_ce: 0.262765
[21:08:48.349] iteration 474 : loss : 0.337693, loss_ce: 0.416486
[21:08:48.605] iteration 475 : loss : 0.238631, loss_ce: 0.208195
[21:08:48.860] iteration 476 : loss : 0.245621, loss_ce: 0.238069
[21:08:49.123] iteration 477 : loss : 0.239565, loss_ce: 0.316493
[21:08:49.379] iteration 478 : loss : 0.275869, loss_ce: 0.279818
[21:08:49.641] iteration 479 : loss : 0.242726, loss_ce: 0.297402
[21:08:49.897] iteration 480 : loss : 0.332308, loss_ce: 0.359122
[21:08:50.198] iteration 481 : loss : 0.303801, loss_ce: 0.284794
[21:08:50.453] iteration 482 : loss : 0.215983, loss_ce: 0.186704
[21:08:50.709] iteration 483 : loss : 0.194537, loss_ce: 0.209911
[21:08:50.966] iteration 484 : loss : 0.322100, loss_ce: 0.286194
[21:08:51.223] iteration 485 : loss : 0.212062, loss_ce: 0.222764
[21:08:51.478] iteration 486 : loss : 0.191818, loss_ce: 0.115050
[21:08:51.733] iteration 487 : loss : 0.206364, loss_ce: 0.119675
[21:08:51.990] iteration 488 : loss : 0.228761, loss_ce: 0.155332
[21:08:52.244] iteration 489 : loss : 0.264497, loss_ce: 0.276770
[21:08:52.500] iteration 490 : loss : 0.183972, loss_ce: 0.176806
[21:08:52.757] iteration 491 : loss : 0.269366, loss_ce: 0.273494
[21:08:53.014] iteration 492 : loss : 0.455799, loss_ce: 0.538160
[21:08:53.269] iteration 493 : loss : 0.244148, loss_ce: 0.234980
[21:08:53.524] iteration 494 : loss : 0.216179, loss_ce: 0.212245
[21:08:53.780] iteration 495 : loss : 0.290137, loss_ce: 0.233254
[21:08:54.038] iteration 496 : loss : 0.278435, loss_ce: 0.281133
[21:08:54.297] iteration 497 : loss : 0.216393, loss_ce: 0.233511
[21:08:54.560] iteration 498 : loss : 0.191525, loss_ce: 0.148933
[21:08:54.830] iteration 499 : loss : 0.333297, loss_ce: 0.374054
[21:08:55.089] iteration 500 : loss : 0.214628, loss_ce: 0.249343
[21:08:55.388] iteration 501 : loss : 0.256220, loss_ce: 0.229941
[21:08:55.645] iteration 502 : loss : 0.165723, loss_ce: 0.161455
[21:08:55.904] iteration 503 : loss : 0.248546, loss_ce: 0.279434
[21:08:56.164] iteration 504 : loss : 0.239388, loss_ce: 0.270123
[21:08:56.419] iteration 505 : loss : 0.199177, loss_ce: 0.176005
[21:08:56.675] iteration 506 : loss : 0.218412, loss_ce: 0.171324
[21:08:56.931] iteration 507 : loss : 0.235565, loss_ce: 0.258750
[21:08:57.186] iteration 508 : loss : 0.208272, loss_ce: 0.235795
[21:08:57.443] iteration 509 : loss : 0.257970, loss_ce: 0.290881
[21:08:57.696] iteration 510 : loss : 0.211169, loss_ce: 0.197586
[21:08:57.954] iteration 511 : loss : 0.262570, loss_ce: 0.304896
[21:08:58.210] iteration 512 : loss : 0.342821, loss_ce: 0.444730
[21:08:58.465] iteration 513 : loss : 0.240508, loss_ce: 0.202890
[21:08:58.724] iteration 514 : loss : 0.324036, loss_ce: 0.372922
[21:08:58.982] iteration 515 : loss : 0.213328, loss_ce: 0.249158
[21:08:59.238] iteration 516 : loss : 0.226941, loss_ce: 0.200823
[21:08:59.495] iteration 517 : loss : 0.249558, loss_ce: 0.278878
[21:08:59.757] iteration 518 : loss : 0.402985, loss_ce: 0.473139
[21:09:00.015] iteration 519 : loss : 0.186944, loss_ce: 0.161953
[21:09:00.273] iteration 520 : loss : 0.246162, loss_ce: 0.250546
[21:09:00.571] iteration 521 : loss : 0.259954, loss_ce: 0.226481
[21:09:00.826] iteration 522 : loss : 0.225722, loss_ce: 0.217070
[21:09:01.081] iteration 523 : loss : 0.341885, loss_ce: 0.395015
[21:09:01.345] iteration 524 : loss : 0.238945, loss_ce: 0.269079
[21:09:01.601] iteration 525 : loss : 0.256752, loss_ce: 0.234154
[21:09:01.859] iteration 526 : loss : 0.239205, loss_ce: 0.247239
[21:09:02.114] iteration 527 : loss : 0.226249, loss_ce: 0.229015
[21:09:02.368] iteration 528 : loss : 0.231630, loss_ce: 0.191262
[21:09:02.626] iteration 529 : loss : 0.278091, loss_ce: 0.331827
[21:09:02.882] iteration 530 : loss : 0.226850, loss_ce: 0.270840
[21:09:03.140] iteration 531 : loss : 0.247221, loss_ce: 0.289032
[21:09:03.397] iteration 532 : loss : 0.213075, loss_ce: 0.225338
[21:09:03.650] iteration 533 : loss : 0.215241, loss_ce: 0.261177
[21:09:03.909] iteration 534 : loss : 0.236562, loss_ce: 0.245518
[21:09:04.164] iteration 535 : loss : 0.211209, loss_ce: 0.186911
[21:09:04.418] iteration 536 : loss : 0.230304, loss_ce: 0.178083
[21:09:04.672] iteration 537 : loss : 0.237819, loss_ce: 0.181707
[21:09:04.929] iteration 538 : loss : 0.197868, loss_ce: 0.171248
[21:09:05.184] iteration 539 : loss : 0.215138, loss_ce: 0.173901
[21:09:05.437] iteration 540 : loss : 0.188420, loss_ce: 0.161180
[21:09:05.740] iteration 541 : loss : 0.214556, loss_ce: 0.152779
[21:09:05.998] iteration 542 : loss : 0.213963, loss_ce: 0.163740
[21:09:06.255] iteration 543 : loss : 0.182298, loss_ce: 0.157409
[21:09:06.510] iteration 544 : loss : 0.258462, loss_ce: 0.208359
[21:09:06.765] iteration 545 : loss : 0.172498, loss_ce: 0.125477
[21:09:07.022] iteration 546 : loss : 0.289436, loss_ce: 0.296546
[21:09:07.281] iteration 547 : loss : 0.452933, loss_ce: 0.533535
[21:09:07.536] iteration 548 : loss : 0.240026, loss_ce: 0.210889
[21:09:07.802] iteration 549 : loss : 0.461517, loss_ce: 0.500295
[21:09:08.057] iteration 550 : loss : 0.228795, loss_ce: 0.243394
[21:09:08.311] iteration 551 : loss : 0.346425, loss_ce: 0.412317
[21:09:08.569] iteration 552 : loss : 0.267158, loss_ce: 0.324573
[21:09:08.825] iteration 553 : loss : 0.248017, loss_ce: 0.255705
[21:09:09.081] iteration 554 : loss : 0.210129, loss_ce: 0.268137
[21:09:09.336] iteration 555 : loss : 0.230082, loss_ce: 0.284930
[21:09:09.592] iteration 556 : loss : 0.287734, loss_ce: 0.264752
[21:09:09.849] iteration 557 : loss : 0.271990, loss_ce: 0.344194
[21:09:10.107] iteration 558 : loss : 0.244773, loss_ce: 0.236263
[21:09:10.363] iteration 559 : loss : 0.243387, loss_ce: 0.283090
[21:09:10.617] iteration 560 : loss : 0.292816, loss_ce: 0.270624
[21:09:10.914] iteration 561 : loss : 0.202991, loss_ce: 0.173045
[21:09:11.171] iteration 562 : loss : 0.234697, loss_ce: 0.250083
[21:09:11.432] iteration 563 : loss : 0.419879, loss_ce: 0.528217
[21:09:11.687] iteration 564 : loss : 0.199294, loss_ce: 0.176279
[21:09:11.951] iteration 565 : loss : 0.293658, loss_ce: 0.207868
[21:09:12.211] iteration 566 : loss : 0.433032, loss_ce: 0.561141
[21:09:12.471] iteration 567 : loss : 0.262425, loss_ce: 0.247737
[21:09:12.726] iteration 568 : loss : 0.226478, loss_ce: 0.158909
[21:09:12.988] iteration 569 : loss : 0.286703, loss_ce: 0.251932
[21:09:13.246] iteration 570 : loss : 0.276547, loss_ce: 0.245730
[21:09:13.499] iteration 571 : loss : 0.207090, loss_ce: 0.167118
[21:09:13.756] iteration 572 : loss : 0.200528, loss_ce: 0.183995
[21:09:14.015] iteration 573 : loss : 0.434242, loss_ce: 0.538488
[21:09:14.275] iteration 574 : loss : 0.271299, loss_ce: 0.250212
[21:09:14.530] iteration 575 : loss : 0.290824, loss_ce: 0.240848
[21:09:14.789] iteration 576 : loss : 0.221953, loss_ce: 0.205913
[21:09:15.045] iteration 577 : loss : 0.237487, loss_ce: 0.197352
[21:09:15.303] iteration 578 : loss : 0.302100, loss_ce: 0.384062
[21:09:15.562] iteration 579 : loss : 0.403613, loss_ce: 0.510573
[21:09:15.818] iteration 580 : loss : 0.322779, loss_ce: 0.402499
[21:09:16.115] iteration 581 : loss : 0.204635, loss_ce: 0.238895
[21:09:16.373] iteration 582 : loss : 0.203941, loss_ce: 0.255369
[21:09:16.630] iteration 583 : loss : 0.241043, loss_ce: 0.235322
[21:09:16.886] iteration 584 : loss : 0.267462, loss_ce: 0.283322
[21:09:17.141] iteration 585 : loss : 0.298459, loss_ce: 0.254389
[21:09:17.398] iteration 586 : loss : 0.253642, loss_ce: 0.255121
[21:09:17.654] iteration 587 : loss : 0.201118, loss_ce: 0.175184
[21:09:17.911] iteration 588 : loss : 0.260326, loss_ce: 0.231054
[21:09:18.167] iteration 589 : loss : 0.272649, loss_ce: 0.246669
[21:09:18.423] iteration 590 : loss : 0.230376, loss_ce: 0.211194
[21:09:18.679] iteration 591 : loss : 0.193245, loss_ce: 0.146215
[21:09:18.936] iteration 592 : loss : 0.334999, loss_ce: 0.367350
[21:09:19.191] iteration 593 : loss : 0.195478, loss_ce: 0.212996
[21:09:19.446] iteration 594 : loss : 0.191742, loss_ce: 0.146794
[21:09:19.709] iteration 595 : loss : 0.535828, loss_ce: 0.700908
[21:09:19.967] iteration 596 : loss : 0.213530, loss_ce: 0.237864
[21:09:20.223] iteration 597 : loss : 0.195995, loss_ce: 0.225412
[21:09:20.483] iteration 598 : loss : 0.248175, loss_ce: 0.302941
[21:09:20.737] iteration 599 : loss : 0.210578, loss_ce: 0.230221
[21:09:20.997] iteration 600 : loss : 0.235018, loss_ce: 0.280163
[21:09:21.301] iteration 601 : loss : 0.204809, loss_ce: 0.238074
[21:09:21.559] iteration 602 : loss : 0.252877, loss_ce: 0.296789
[21:09:21.816] iteration 603 : loss : 0.281311, loss_ce: 0.267705
[21:09:22.073] iteration 604 : loss : 0.240922, loss_ce: 0.226321
[21:09:22.332] iteration 605 : loss : 0.298349, loss_ce: 0.339405
[21:09:22.592] iteration 606 : loss : 0.301572, loss_ce: 0.355294
[21:09:22.850] iteration 607 : loss : 0.316788, loss_ce: 0.362139
[21:09:23.109] iteration 608 : loss : 0.195569, loss_ce: 0.199094
[21:09:23.367] iteration 609 : loss : 0.197389, loss_ce: 0.180217
[21:09:23.622] iteration 610 : loss : 0.336608, loss_ce: 0.362702
[21:09:23.880] iteration 611 : loss : 0.164934, loss_ce: 0.164284
[21:09:24.137] iteration 612 : loss : 0.187805, loss_ce: 0.155104
[21:09:24.393] iteration 613 : loss : 0.219428, loss_ce: 0.217640
[21:09:24.649] iteration 614 : loss : 0.331710, loss_ce: 0.391059
[21:09:24.905] iteration 615 : loss : 0.220642, loss_ce: 0.236053
[21:09:25.162] iteration 616 : loss : 0.236088, loss_ce: 0.259443
[21:09:25.421] iteration 617 : loss : 0.291096, loss_ce: 0.337303
[21:09:25.680] iteration 618 : loss : 0.233454, loss_ce: 0.197139
[21:09:25.941] iteration 619 : loss : 0.310636, loss_ce: 0.301225
[21:09:26.196] iteration 620 : loss : 0.268257, loss_ce: 0.223533
[21:09:26.494] iteration 621 : loss : 0.187131, loss_ce: 0.174654
[21:09:26.752] iteration 622 : loss : 0.177018, loss_ce: 0.144641
[21:09:27.013] iteration 623 : loss : 0.404874, loss_ce: 0.538088
[21:09:27.272] iteration 624 : loss : 0.273938, loss_ce: 0.347427
[21:09:27.529] iteration 625 : loss : 0.212862, loss_ce: 0.204512
[21:09:27.789] iteration 626 : loss : 0.269862, loss_ce: 0.309302
[21:09:28.047] iteration 627 : loss : 0.249271, loss_ce: 0.311330
[21:09:28.308] iteration 628 : loss : 0.255542, loss_ce: 0.321338
[21:09:28.569] iteration 629 : loss : 0.322812, loss_ce: 0.400724
[21:09:28.828] iteration 630 : loss : 0.188771, loss_ce: 0.181927
[21:09:29.085] iteration 631 : loss : 0.329977, loss_ce: 0.401289
[21:09:29.342] iteration 632 : loss : 0.202679, loss_ce: 0.190386
[21:09:29.600] iteration 633 : loss : 0.237596, loss_ce: 0.249227
[21:09:29.857] iteration 634 : loss : 0.234365, loss_ce: 0.272475
[21:09:30.113] iteration 635 : loss : 0.253154, loss_ce: 0.220665
[21:09:30.370] iteration 636 : loss : 0.214688, loss_ce: 0.256699
[21:09:30.627] iteration 637 : loss : 0.190880, loss_ce: 0.162691
[21:09:30.882] iteration 638 : loss : 0.214806, loss_ce: 0.220721
[21:09:31.142] iteration 639 : loss : 0.254330, loss_ce: 0.266024
[21:09:31.410] iteration 640 : loss : 0.195210, loss_ce: 0.221629
[21:09:31.707] iteration 641 : loss : 0.252136, loss_ce: 0.277471
[21:09:31.970] iteration 642 : loss : 0.201468, loss_ce: 0.154307
[21:09:32.228] iteration 643 : loss : 0.198863, loss_ce: 0.177538
[21:09:32.483] iteration 644 : loss : 0.216498, loss_ce: 0.163302
[21:09:32.738] iteration 645 : loss : 0.182522, loss_ce: 0.210842
[21:09:32.992] iteration 646 : loss : 0.166646, loss_ce: 0.133703
[21:09:33.250] iteration 647 : loss : 0.268639, loss_ce: 0.305756
[21:09:33.509] iteration 648 : loss : 0.486808, loss_ce: 0.662217
[21:09:33.769] iteration 649 : loss : 0.472373, loss_ce: 0.601497
[21:09:34.024] iteration 650 : loss : 0.222231, loss_ce: 0.221583
[21:09:34.280] iteration 651 : loss : 0.347478, loss_ce: 0.399938
[21:09:34.534] iteration 652 : loss : 0.219844, loss_ce: 0.222088
[21:09:34.790] iteration 653 : loss : 0.307775, loss_ce: 0.353339
[21:09:35.044] iteration 654 : loss : 0.288548, loss_ce: 0.327127
[21:09:35.298] iteration 655 : loss : 0.233414, loss_ce: 0.280152
[21:09:35.554] iteration 656 : loss : 0.232735, loss_ce: 0.239129
[21:09:35.809] iteration 657 : loss : 0.202210, loss_ce: 0.216643
[21:09:36.074] iteration 658 : loss : 0.385655, loss_ce: 0.426251
[21:09:36.344] iteration 659 : loss : 0.218672, loss_ce: 0.237263
[21:09:36.601] iteration 660 : loss : 0.189009, loss_ce: 0.162523
[21:09:36.898] iteration 661 : loss : 0.217918, loss_ce: 0.209976
[21:09:37.154] iteration 662 : loss : 0.190157, loss_ce: 0.161557
[21:09:37.411] iteration 663 : loss : 0.214808, loss_ce: 0.199614
[21:09:37.666] iteration 664 : loss : 0.163270, loss_ce: 0.124896
[21:09:37.925] iteration 665 : loss : 0.330193, loss_ce: 0.369664
[21:09:38.182] iteration 666 : loss : 0.346588, loss_ce: 0.405226
[21:09:38.443] iteration 667 : loss : 0.225208, loss_ce: 0.206810
[21:09:38.744] iteration 668 : loss : 0.181341, loss_ce: 0.166307
[21:09:39.021] iteration 669 : loss : 0.284104, loss_ce: 0.352377
[21:09:39.302] iteration 670 : loss : 0.201412, loss_ce: 0.168881
[21:09:39.606] iteration 671 : loss : 0.212176, loss_ce: 0.229376
[21:09:39.897] iteration 672 : loss : 0.182186, loss_ce: 0.145616
[21:09:40.179] iteration 673 : loss : 0.253986, loss_ce: 0.302399
[21:09:40.440] iteration 674 : loss : 0.250988, loss_ce: 0.288022
[21:09:40.713] iteration 675 : loss : 0.196573, loss_ce: 0.208036
[21:09:40.989] iteration 676 : loss : 0.275874, loss_ce: 0.240672
[21:09:41.254] iteration 677 : loss : 0.214157, loss_ce: 0.235762
[21:09:41.509] iteration 678 : loss : 0.277290, loss_ce: 0.201854
[21:09:41.765] iteration 679 : loss : 0.310289, loss_ce: 0.378639
[21:09:42.025] iteration 680 : loss : 0.301628, loss_ce: 0.380928
[21:09:42.335] iteration 681 : loss : 0.198790, loss_ce: 0.150411
[21:09:42.596] iteration 682 : loss : 0.235690, loss_ce: 0.212733
[21:09:42.857] iteration 683 : loss : 0.421838, loss_ce: 0.536009
[21:09:43.115] iteration 684 : loss : 0.254843, loss_ce: 0.308243
[21:09:43.371] iteration 685 : loss : 0.225269, loss_ce: 0.231135
[21:09:43.627] iteration 686 : loss : 0.266297, loss_ce: 0.272946
[21:09:43.884] iteration 687 : loss : 0.228750, loss_ce: 0.197384
[21:09:44.165] iteration 688 : loss : 0.284609, loss_ce: 0.354809
[21:09:44.452] iteration 689 : loss : 0.170985, loss_ce: 0.167999
[21:09:44.737] iteration 690 : loss : 0.222594, loss_ce: 0.184705
[21:09:45.007] iteration 691 : loss : 0.242344, loss_ce: 0.245983
[21:09:45.294] iteration 692 : loss : 0.182120, loss_ce: 0.169713
[21:09:45.576] iteration 693 : loss : 0.338331, loss_ce: 0.434676
[21:09:45.865] iteration 694 : loss : 0.240775, loss_ce: 0.258089
[21:09:46.125] iteration 695 : loss : 0.243974, loss_ce: 0.257511
[21:09:46.384] iteration 696 : loss : 0.234756, loss_ce: 0.240815
[21:09:46.638] iteration 697 : loss : 0.236217, loss_ce: 0.230395
[21:09:46.912] iteration 698 : loss : 0.211652, loss_ce: 0.253756
[21:09:47.206] iteration 699 : loss : 0.219425, loss_ce: 0.263291
[21:09:47.482] iteration 700 : loss : 0.190174, loss_ce: 0.223815
[21:09:47.815] iteration 701 : loss : 0.221166, loss_ce: 0.248985
[21:09:48.080] iteration 702 : loss : 0.196863, loss_ce: 0.207526
[21:09:48.339] iteration 703 : loss : 0.356907, loss_ce: 0.392690
[21:09:48.628] iteration 704 : loss : 0.252074, loss_ce: 0.224610
[21:09:48.892] iteration 705 : loss : 0.210019, loss_ce: 0.163224
[21:09:49.151] iteration 706 : loss : 0.232056, loss_ce: 0.182508
[21:09:49.415] iteration 707 : loss : 0.262801, loss_ce: 0.306960
[21:09:49.677] iteration 708 : loss : 0.176334, loss_ce: 0.193716
[21:09:49.975] iteration 709 : loss : 0.357300, loss_ce: 0.432398
[21:09:50.267] iteration 710 : loss : 0.199992, loss_ce: 0.197552
[21:09:50.557] iteration 711 : loss : 0.285647, loss_ce: 0.248592
[21:09:50.814] iteration 712 : loss : 0.192385, loss_ce: 0.191572
[21:09:51.072] iteration 713 : loss : 0.258347, loss_ce: 0.298147
[21:09:51.330] iteration 714 : loss : 0.250842, loss_ce: 0.240868
[21:09:51.584] iteration 715 : loss : 0.222739, loss_ce: 0.224321
[21:09:51.840] iteration 716 : loss : 0.208594, loss_ce: 0.237716
[21:09:52.098] iteration 717 : loss : 0.316712, loss_ce: 0.391826
[21:09:52.354] iteration 718 : loss : 0.190791, loss_ce: 0.203214
[21:09:52.610] iteration 719 : loss : 0.186382, loss_ce: 0.149189
[21:09:52.868] iteration 720 : loss : 0.190461, loss_ce: 0.228465
[21:09:53.169] iteration 721 : loss : 0.189913, loss_ce: 0.220298
[21:09:53.427] iteration 722 : loss : 0.356936, loss_ce: 0.448568
[21:09:53.683] iteration 723 : loss : 0.203727, loss_ce: 0.239118
[21:09:53.940] iteration 724 : loss : 0.211144, loss_ce: 0.228639
[21:09:54.195] iteration 725 : loss : 0.215552, loss_ce: 0.201333
[21:09:54.452] iteration 726 : loss : 0.248101, loss_ce: 0.234927
[21:09:54.708] iteration 727 : loss : 0.196650, loss_ce: 0.202776
[21:09:54.963] iteration 728 : loss : 0.219951, loss_ce: 0.215146
[21:09:55.217] iteration 729 : loss : 0.200911, loss_ce: 0.204735
[21:09:55.473] iteration 730 : loss : 0.175127, loss_ce: 0.175692
[21:09:55.727] iteration 731 : loss : 0.233294, loss_ce: 0.184841
[21:09:55.982] iteration 732 : loss : 0.188581, loss_ce: 0.220988
[21:09:56.237] iteration 733 : loss : 0.219893, loss_ce: 0.193537
[21:09:56.492] iteration 734 : loss : 0.181183, loss_ce: 0.130132
[21:09:56.749] iteration 735 : loss : 0.249025, loss_ce: 0.213232
[21:09:57.005] iteration 736 : loss : 0.194072, loss_ce: 0.217015
[21:09:57.263] iteration 737 : loss : 0.487507, loss_ce: 0.651505
[21:09:57.519] iteration 738 : loss : 0.197633, loss_ce: 0.218579
[21:09:57.779] iteration 739 : loss : 0.474531, loss_ce: 0.630643
[21:09:58.033] iteration 740 : loss : 0.190281, loss_ce: 0.159173
[21:09:58.334] iteration 741 : loss : 0.210883, loss_ce: 0.260071
[21:09:58.592] iteration 742 : loss : 0.242329, loss_ce: 0.275056
[21:09:58.847] iteration 743 : loss : 0.209393, loss_ce: 0.253261
[21:09:59.104] iteration 744 : loss : 0.217788, loss_ce: 0.228079
[21:09:59.360] iteration 745 : loss : 0.293221, loss_ce: 0.244718
[21:09:59.618] iteration 746 : loss : 0.209750, loss_ce: 0.262278
[21:09:59.871] iteration 747 : loss : 0.191552, loss_ce: 0.161462
[21:10:00.128] iteration 748 : loss : 0.240525, loss_ce: 0.233960
[21:10:00.381] iteration 749 : loss : 0.207209, loss_ce: 0.164215
[21:10:00.637] iteration 750 : loss : 0.266338, loss_ce: 0.209530
[21:10:00.898] iteration 751 : loss : 0.296482, loss_ce: 0.346663
[21:10:01.154] iteration 752 : loss : 0.226978, loss_ce: 0.255312
[21:10:01.414] iteration 753 : loss : 0.426257, loss_ce: 0.476092
[21:10:01.673] iteration 754 : loss : 0.237833, loss_ce: 0.260066
[21:10:01.927] iteration 755 : loss : 0.209445, loss_ce: 0.185003
[21:10:02.181] iteration 756 : loss : 0.249019, loss_ce: 0.202556
[21:10:02.440] iteration 757 : loss : 0.287991, loss_ce: 0.325818
[21:10:02.695] iteration 758 : loss : 0.247238, loss_ce: 0.259983
[21:10:02.950] iteration 759 : loss : 0.199924, loss_ce: 0.210444
[21:10:03.208] iteration 760 : loss : 0.255628, loss_ce: 0.251414
[21:10:03.515] iteration 761 : loss : 0.257623, loss_ce: 0.342675
[21:10:03.770] iteration 762 : loss : 0.209603, loss_ce: 0.246062
[21:10:04.025] iteration 763 : loss : 0.190021, loss_ce: 0.201152
[21:10:04.281] iteration 764 : loss : 0.185239, loss_ce: 0.198761
[21:10:04.535] iteration 765 : loss : 0.183971, loss_ce: 0.182155
[21:10:04.793] iteration 766 : loss : 0.231632, loss_ce: 0.222809
[21:10:05.050] iteration 767 : loss : 0.227466, loss_ce: 0.256084
[21:10:05.304] iteration 768 : loss : 0.210120, loss_ce: 0.231496
[21:10:05.560] iteration 769 : loss : 0.234399, loss_ce: 0.197402
[21:10:05.816] iteration 770 : loss : 0.313339, loss_ce: 0.235564
[21:10:06.070] iteration 771 : loss : 0.195207, loss_ce: 0.214987
[21:10:06.326] iteration 772 : loss : 0.195890, loss_ce: 0.187895
[21:10:06.581] iteration 773 : loss : 0.218058, loss_ce: 0.218599
[21:10:06.841] iteration 774 : loss : 0.447220, loss_ce: 0.571503
[21:10:07.102] iteration 775 : loss : 0.439753, loss_ce: 0.533379
[21:10:07.357] iteration 776 : loss : 0.179384, loss_ce: 0.213409
[21:10:07.612] iteration 777 : loss : 0.200713, loss_ce: 0.204814
[21:10:07.871] iteration 778 : loss : 0.241877, loss_ce: 0.312961
[21:10:08.128] iteration 779 : loss : 0.333364, loss_ce: 0.361700
[21:10:08.385] iteration 780 : loss : 0.212756, loss_ce: 0.271750
[21:10:08.688] iteration 781 : loss : 0.242776, loss_ce: 0.295049
[21:10:08.946] iteration 782 : loss : 0.205628, loss_ce: 0.266461
[21:10:09.202] iteration 783 : loss : 0.194371, loss_ce: 0.228722
[21:10:09.460] iteration 784 : loss : 0.245383, loss_ce: 0.306469
[21:10:09.717] iteration 785 : loss : 0.182957, loss_ce: 0.175131
[21:10:09.972] iteration 786 : loss : 0.200200, loss_ce: 0.201625
[21:10:10.250] iteration 787 : loss : 0.199215, loss_ce: 0.202189
[21:10:10.536] iteration 788 : loss : 0.209204, loss_ce: 0.150708
[21:10:10.822] iteration 789 : loss : 0.191376, loss_ce: 0.172108
[21:10:11.111] iteration 790 : loss : 0.181089, loss_ce: 0.144156
[21:10:11.398] iteration 791 : loss : 0.265668, loss_ce: 0.196505
[21:10:11.687] iteration 792 : loss : 0.269427, loss_ce: 0.259378
[21:10:11.947] iteration 793 : loss : 0.201958, loss_ce: 0.133420
[21:10:12.207] iteration 794 : loss : 0.234430, loss_ce: 0.255844
[21:10:12.466] iteration 795 : loss : 0.184215, loss_ce: 0.159724
[21:10:12.729] iteration 796 : loss : 0.366911, loss_ce: 0.428834
[21:10:12.992] iteration 797 : loss : 0.222665, loss_ce: 0.255453
[21:10:13.246] iteration 798 : loss : 0.208250, loss_ce: 0.191644
[21:10:13.503] iteration 799 : loss : 0.196218, loss_ce: 0.166796
[21:10:13.768] iteration 800 : loss : 0.242663, loss_ce: 0.249504
[21:10:14.108] iteration 801 : loss : 0.202632, loss_ce: 0.210116
[21:10:14.394] iteration 802 : loss : 0.204435, loss_ce: 0.234878
[21:10:14.667] iteration 803 : loss : 0.187414, loss_ce: 0.238690
[21:10:14.926] iteration 804 : loss : 0.227487, loss_ce: 0.224995
[21:10:15.192] iteration 805 : loss : 0.193874, loss_ce: 0.195434
[21:10:15.455] iteration 806 : loss : 0.219155, loss_ce: 0.231618
[21:10:15.722] iteration 807 : loss : 0.307695, loss_ce: 0.287789
[21:10:15.982] iteration 808 : loss : 0.205628, loss_ce: 0.242158
[21:10:16.241] iteration 809 : loss : 0.180851, loss_ce: 0.170784
[21:10:16.497] iteration 810 : loss : 0.247641, loss_ce: 0.269420
[21:10:16.751] iteration 811 : loss : 0.187120, loss_ce: 0.154351
[21:10:17.011] iteration 812 : loss : 0.205379, loss_ce: 0.238817
[21:10:17.269] iteration 813 : loss : 0.165945, loss_ce: 0.127762
[21:10:17.555] iteration 814 : loss : 0.211170, loss_ce: 0.189347
[21:10:17.848] iteration 815 : loss : 0.182446, loss_ce: 0.201473
[21:10:18.136] iteration 816 : loss : 0.232541, loss_ce: 0.251529
[21:10:18.405] iteration 817 : loss : 0.186541, loss_ce: 0.156149
[21:10:18.663] iteration 818 : loss : 0.190842, loss_ce: 0.161286
[21:10:18.934] iteration 819 : loss : 0.166136, loss_ce: 0.141524
[21:10:19.189] iteration 820 : loss : 0.199237, loss_ce: 0.189657
[21:10:19.501] iteration 821 : loss : 0.237564, loss_ce: 0.237762
[21:10:19.787] iteration 822 : loss : 0.174446, loss_ce: 0.166081
[21:10:20.077] iteration 823 : loss : 0.285985, loss_ce: 0.355959
[21:10:20.355] iteration 824 : loss : 0.189561, loss_ce: 0.186048
[21:10:20.615] iteration 825 : loss : 0.276386, loss_ce: 0.240024
[21:10:20.883] iteration 826 : loss : 0.204664, loss_ce: 0.187733
[21:10:21.143] iteration 827 : loss : 0.182639, loss_ce: 0.163794
[21:10:21.419] iteration 828 : loss : 0.311140, loss_ce: 0.393166
[21:10:21.680] iteration 829 : loss : 0.229438, loss_ce: 0.280192
[21:10:21.940] iteration 830 : loss : 0.186148, loss_ce: 0.211088
[21:10:22.199] iteration 831 : loss : 0.300852, loss_ce: 0.349661
[21:10:22.462] iteration 832 : loss : 0.231079, loss_ce: 0.226903
[21:10:22.723] iteration 833 : loss : 0.202939, loss_ce: 0.260289
[21:10:22.982] iteration 834 : loss : 0.177953, loss_ce: 0.169077
[21:10:23.238] iteration 835 : loss : 0.191545, loss_ce: 0.168429
[21:10:23.496] iteration 836 : loss : 0.275692, loss_ce: 0.329390
[21:10:23.759] iteration 837 : loss : 0.193968, loss_ce: 0.218510
[21:10:24.015] iteration 838 : loss : 0.199919, loss_ce: 0.196868
[21:10:24.278] iteration 839 : loss : 0.245031, loss_ce: 0.325793
[21:10:24.541] iteration 840 : loss : 0.393736, loss_ce: 0.510354
[21:10:24.848] iteration 841 : loss : 0.269904, loss_ce: 0.286106
[21:10:25.105] iteration 842 : loss : 0.312298, loss_ce: 0.291227
[21:10:25.367] iteration 843 : loss : 0.381690, loss_ce: 0.439813
[21:10:25.632] iteration 844 : loss : 0.334936, loss_ce: 0.456907
[21:10:25.888] iteration 845 : loss : 0.212233, loss_ce: 0.233208
[21:10:26.149] iteration 846 : loss : 0.243658, loss_ce: 0.233883
[21:10:26.410] iteration 847 : loss : 0.254923, loss_ce: 0.247464
[21:10:26.669] iteration 848 : loss : 0.207406, loss_ce: 0.256077
[21:10:26.927] iteration 849 : loss : 0.237806, loss_ce: 0.228642
[21:10:27.184] iteration 850 : loss : 0.229672, loss_ce: 0.258659
[21:10:27.443] iteration 851 : loss : 0.191927, loss_ce: 0.173200
[21:10:27.702] iteration 852 : loss : 0.184277, loss_ce: 0.163587
[21:10:27.959] iteration 853 : loss : 0.213497, loss_ce: 0.150111
[21:10:28.217] iteration 854 : loss : 0.170287, loss_ce: 0.168966
[21:10:28.474] iteration 855 : loss : 0.237099, loss_ce: 0.259831
[21:10:28.737] iteration 856 : loss : 0.525756, loss_ce: 0.645950
[21:10:28.993] iteration 857 : loss : 0.172113, loss_ce: 0.192301
[21:10:29.252] iteration 858 : loss : 0.200304, loss_ce: 0.199890
[21:10:29.507] iteration 859 : loss : 0.167031, loss_ce: 0.132082
[21:10:29.765] iteration 860 : loss : 0.196910, loss_ce: 0.149912
[21:10:30.067] iteration 861 : loss : 0.155942, loss_ce: 0.120165
[21:10:30.322] iteration 862 : loss : 0.204740, loss_ce: 0.150751
[21:10:30.582] iteration 863 : loss : 0.267959, loss_ce: 0.326864
[21:10:30.838] iteration 864 : loss : 0.189362, loss_ce: 0.221833
[21:10:31.098] iteration 865 : loss : 0.434101, loss_ce: 0.543387
[21:10:31.353] iteration 866 : loss : 0.171461, loss_ce: 0.162000
[21:10:31.613] iteration 867 : loss : 0.224664, loss_ce: 0.224721
[21:10:31.872] iteration 868 : loss : 0.233244, loss_ce: 0.291052
[21:10:32.134] iteration 869 : loss : 0.267629, loss_ce: 0.227746
[21:10:32.425] iteration 870 : loss : 0.294966, loss_ce: 0.350103
[21:10:32.710] iteration 871 : loss : 0.268262, loss_ce: 0.294596
[21:10:32.996] iteration 872 : loss : 0.199491, loss_ce: 0.212667
[21:10:33.254] iteration 873 : loss : 0.172345, loss_ce: 0.172665
[21:10:33.514] iteration 874 : loss : 0.188410, loss_ce: 0.210974
[21:10:33.810] iteration 875 : loss : 0.148571, loss_ce: 0.141228
[21:10:34.114] iteration 876 : loss : 0.234034, loss_ce: 0.253800
[21:10:34.384] iteration 877 : loss : 0.185213, loss_ce: 0.142834
[21:10:34.673] iteration 878 : loss : 0.470096, loss_ce: 0.636459
[21:10:34.945] iteration 879 : loss : 0.241257, loss_ce: 0.229035
[21:10:35.219] iteration 880 : loss : 0.183983, loss_ce: 0.170698
[21:10:35.559] iteration 881 : loss : 0.186652, loss_ce: 0.176908
[21:10:35.838] iteration 882 : loss : 0.168538, loss_ce: 0.168349
[21:10:36.140] iteration 883 : loss : 0.249529, loss_ce: 0.239400
[21:10:36.420] iteration 884 : loss : 0.203786, loss_ce: 0.230284
[21:10:36.715] iteration 885 : loss : 0.222874, loss_ce: 0.216669
[21:10:36.992] iteration 886 : loss : 0.209682, loss_ce: 0.260723
[21:10:37.264] iteration 887 : loss : 0.199087, loss_ce: 0.226164
[21:10:37.524] iteration 888 : loss : 0.213514, loss_ce: 0.257563
[21:10:37.793] iteration 889 : loss : 0.183196, loss_ce: 0.219938
[21:10:38.064] iteration 890 : loss : 0.302153, loss_ce: 0.369809
[21:10:38.320] iteration 891 : loss : 0.187964, loss_ce: 0.205491
[21:10:38.577] iteration 892 : loss : 0.203829, loss_ce: 0.172652
[21:10:38.835] iteration 893 : loss : 0.187431, loss_ce: 0.220077
[21:10:39.093] iteration 894 : loss : 0.242957, loss_ce: 0.249622
[21:10:39.353] iteration 895 : loss : 0.187631, loss_ce: 0.225650
[21:10:39.620] iteration 896 : loss : 0.214531, loss_ce: 0.246059
[21:10:39.885] iteration 897 : loss : 0.222792, loss_ce: 0.249506
[21:10:40.178] iteration 898 : loss : 0.177679, loss_ce: 0.151873
[21:10:40.467] iteration 899 : loss : 0.182119, loss_ce: 0.199138
[21:10:40.771] iteration 900 : loss : 0.189187, loss_ce: 0.208591
[21:10:41.108] iteration 901 : loss : 0.305827, loss_ce: 0.376804
[21:10:41.400] iteration 902 : loss : 0.174645, loss_ce: 0.159953
[21:10:41.693] iteration 903 : loss : 0.190806, loss_ce: 0.196533
[21:10:41.989] iteration 904 : loss : 0.206933, loss_ce: 0.238114
[21:10:42.282] iteration 905 : loss : 0.340980, loss_ce: 0.434130
[21:10:42.562] iteration 906 : loss : 0.180780, loss_ce: 0.222942
[21:10:42.818] iteration 907 : loss : 0.205821, loss_ce: 0.197506
[21:10:43.097] iteration 908 : loss : 0.270166, loss_ce: 0.231804
[21:10:43.377] iteration 909 : loss : 0.180730, loss_ce: 0.227514
[21:10:43.656] iteration 910 : loss : 0.224189, loss_ce: 0.263428
[21:10:43.945] iteration 911 : loss : 0.326847, loss_ce: 0.393209
[21:10:44.237] iteration 912 : loss : 0.214390, loss_ce: 0.203821
[21:10:44.533] iteration 913 : loss : 0.334619, loss_ce: 0.433207
[21:10:44.824] iteration 914 : loss : 0.217994, loss_ce: 0.270093
[21:10:45.084] iteration 915 : loss : 0.184114, loss_ce: 0.218069
[21:10:45.342] iteration 916 : loss : 0.203294, loss_ce: 0.190477
[21:10:45.597] iteration 917 : loss : 0.239476, loss_ce: 0.184239
[21:10:45.858] iteration 918 : loss : 0.347895, loss_ce: 0.403766
[21:10:46.116] iteration 919 : loss : 0.242892, loss_ce: 0.224990
[21:10:46.372] iteration 920 : loss : 0.187146, loss_ce: 0.149154
[21:10:46.674] iteration 921 : loss : 0.197275, loss_ce: 0.235218
[21:10:46.928] iteration 922 : loss : 0.205290, loss_ce: 0.182429
[21:10:47.184] iteration 923 : loss : 0.265707, loss_ce: 0.186167
[21:10:47.443] iteration 924 : loss : 0.212351, loss_ce: 0.248093
[21:10:47.701] iteration 925 : loss : 0.285374, loss_ce: 0.334706
[21:10:47.958] iteration 926 : loss : 0.191048, loss_ce: 0.222990
[21:10:48.214] iteration 927 : loss : 0.242998, loss_ce: 0.229707
[21:10:48.470] iteration 928 : loss : 0.225852, loss_ce: 0.201873
[21:10:48.724] iteration 929 : loss : 0.224783, loss_ce: 0.182778
[21:10:48.982] iteration 930 : loss : 0.195252, loss_ce: 0.230402
[21:10:49.237] iteration 931 : loss : 0.199321, loss_ce: 0.216433
[21:10:49.496] iteration 932 : loss : 0.279810, loss_ce: 0.315180
[21:10:49.755] iteration 933 : loss : 0.274973, loss_ce: 0.314620
[21:10:50.011] iteration 934 : loss : 0.173877, loss_ce: 0.200082
[21:10:50.292] iteration 935 : loss : 0.314112, loss_ce: 0.399868
[21:10:50.585] iteration 936 : loss : 0.240024, loss_ce: 0.244867
[21:10:50.874] iteration 937 : loss : 0.256906, loss_ce: 0.318118
[21:10:51.148] iteration 938 : loss : 0.288240, loss_ce: 0.365672
[21:10:51.405] iteration 939 : loss : 0.199800, loss_ce: 0.208698
[21:10:51.663] iteration 940 : loss : 0.186289, loss_ce: 0.223617
[21:10:51.959] iteration 941 : loss : 0.234050, loss_ce: 0.254517
[21:10:52.216] iteration 942 : loss : 0.173419, loss_ce: 0.186525
[21:10:52.474] iteration 943 : loss : 0.253409, loss_ce: 0.254225
[21:10:52.760] iteration 944 : loss : 0.262625, loss_ce: 0.228967
[21:10:53.052] iteration 945 : loss : 0.209821, loss_ce: 0.242266
[21:10:53.341] iteration 946 : loss : 0.198139, loss_ce: 0.160265
[21:10:53.606] iteration 947 : loss : 0.226167, loss_ce: 0.204658
[21:10:53.893] iteration 948 : loss : 0.465250, loss_ce: 0.602855
[21:10:54.181] iteration 949 : loss : 0.204761, loss_ce: 0.155561
[21:10:54.470] iteration 950 : loss : 0.192026, loss_ce: 0.213001
[21:10:54.763] iteration 951 : loss : 0.476082, loss_ce: 0.643944
[21:10:55.053] iteration 952 : loss : 0.203334, loss_ce: 0.246307
[21:10:55.345] iteration 953 : loss : 0.276214, loss_ce: 0.333211
[21:10:55.632] iteration 954 : loss : 0.195438, loss_ce: 0.136611
[21:10:55.891] iteration 955 : loss : 0.267721, loss_ce: 0.277168
[21:10:56.153] iteration 956 : loss : 0.281684, loss_ce: 0.361499
[21:10:56.410] iteration 957 : loss : 0.236108, loss_ce: 0.246198
[21:10:56.668] iteration 958 : loss : 0.187159, loss_ce: 0.191869
[21:10:56.925] iteration 959 : loss : 0.178363, loss_ce: 0.213247
[21:10:57.188] iteration 960 : loss : 0.200356, loss_ce: 0.238426
[21:10:57.488] iteration 961 : loss : 0.153049, loss_ce: 0.112805
[21:10:57.751] iteration 962 : loss : 0.218633, loss_ce: 0.237809
[21:10:58.010] iteration 963 : loss : 0.232067, loss_ce: 0.217197
[21:10:58.268] iteration 964 : loss : 0.348204, loss_ce: 0.438675
[21:10:58.525] iteration 965 : loss : 0.183045, loss_ce: 0.136778
[21:10:58.781] iteration 966 : loss : 0.183502, loss_ce: 0.206642
[21:10:59.038] iteration 967 : loss : 0.191696, loss_ce: 0.195160
[21:10:59.294] iteration 968 : loss : 0.176877, loss_ce: 0.146959
[21:10:59.552] iteration 969 : loss : 0.197758, loss_ce: 0.155251
[21:10:59.819] iteration 970 : loss : 0.196747, loss_ce: 0.183995
[21:11:00.117] iteration 971 : loss : 0.338231, loss_ce: 0.345482
[21:11:00.409] iteration 972 : loss : 0.201670, loss_ce: 0.161422
[21:11:00.701] iteration 973 : loss : 0.186307, loss_ce: 0.153034
[21:11:00.989] iteration 974 : loss : 0.212079, loss_ce: 0.163367
[21:11:01.274] iteration 975 : loss : 0.277791, loss_ce: 0.232250
[21:11:01.554] iteration 976 : loss : 0.147913, loss_ce: 0.109303
[21:11:01.814] iteration 977 : loss : 0.177245, loss_ce: 0.199985
[21:11:02.074] iteration 978 : loss : 0.195923, loss_ce: 0.177872
[21:11:02.331] iteration 979 : loss : 0.158512, loss_ce: 0.138113
[21:11:02.587] iteration 980 : loss : 0.161736, loss_ce: 0.185540
[21:11:02.916] iteration 981 : loss : 0.184828, loss_ce: 0.196107
[21:11:03.203] iteration 982 : loss : 0.172717, loss_ce: 0.194116
[21:11:03.492] iteration 983 : loss : 0.217128, loss_ce: 0.195379
[21:11:03.751] iteration 984 : loss : 0.167154, loss_ce: 0.164931
[21:11:04.009] iteration 985 : loss : 0.177881, loss_ce: 0.179590
[21:11:04.267] iteration 986 : loss : 0.216660, loss_ce: 0.221410
[21:11:04.528] iteration 987 : loss : 0.426754, loss_ce: 0.470909
[21:11:04.786] iteration 988 : loss : 0.174373, loss_ce: 0.148049
[21:11:05.043] iteration 989 : loss : 0.160225, loss_ce: 0.146472
[21:11:05.303] iteration 990 : loss : 0.247807, loss_ce: 0.287907
[21:11:05.566] iteration 991 : loss : 0.366287, loss_ce: 0.440986
[21:11:05.821] iteration 992 : loss : 0.176640, loss_ce: 0.198779
[21:11:06.077] iteration 993 : loss : 0.309741, loss_ce: 0.376530
[21:11:06.338] iteration 994 : loss : 0.244397, loss_ce: 0.279671
[21:11:06.595] iteration 995 : loss : 0.188070, loss_ce: 0.204623
[21:11:06.853] iteration 996 : loss : 0.289708, loss_ce: 0.277424
[21:11:07.113] iteration 997 : loss : 0.238629, loss_ce: 0.293854
[21:11:07.370] iteration 998 : loss : 0.180340, loss_ce: 0.225563
[21:11:07.628] iteration 999 : loss : 0.296151, loss_ce: 0.255656
[21:11:07.885] iteration 1000 : loss : 0.228442, loss_ce: 0.225044
[21:11:08.192] iteration 1001 : loss : 0.203506, loss_ce: 0.184045
[21:11:08.449] iteration 1002 : loss : 0.281035, loss_ce: 0.339779
[21:11:08.707] iteration 1003 : loss : 0.192661, loss_ce: 0.212862
[21:11:08.963] iteration 1004 : loss : 0.136556, loss_ce: 0.131470
[21:11:09.221] iteration 1005 : loss : 0.230115, loss_ce: 0.218663
[21:11:09.479] iteration 1006 : loss : 0.292487, loss_ce: 0.330197
[21:11:09.740] iteration 1007 : loss : 0.223435, loss_ce: 0.272824
[21:11:09.996] iteration 1008 : loss : 0.165613, loss_ce: 0.156956
[21:11:10.254] iteration 1009 : loss : 0.210476, loss_ce: 0.230515
[21:11:10.512] iteration 1010 : loss : 0.163265, loss_ce: 0.162883
[21:11:10.768] iteration 1011 : loss : 0.278805, loss_ce: 0.288839
[21:11:11.026] iteration 1012 : loss : 0.210606, loss_ce: 0.193148
[21:11:11.285] iteration 1013 : loss : 0.220942, loss_ce: 0.256315
[21:11:11.550] iteration 1014 : loss : 0.354972, loss_ce: 0.386975
[21:11:11.807] iteration 1015 : loss : 0.239965, loss_ce: 0.222416
[21:11:12.064] iteration 1016 : loss : 0.213363, loss_ce: 0.253367
[21:11:12.326] iteration 1017 : loss : 0.182293, loss_ce: 0.218964
[21:11:12.583] iteration 1018 : loss : 0.202635, loss_ce: 0.192763
[21:11:12.845] iteration 1019 : loss : 0.243570, loss_ce: 0.250804
[21:11:13.105] iteration 1020 : loss : 0.216720, loss_ce: 0.227421
[21:11:13.414] iteration 1021 : loss : 0.213021, loss_ce: 0.187255
[21:11:13.673] iteration 1022 : loss : 0.175679, loss_ce: 0.208644
[21:11:13.933] iteration 1023 : loss : 0.234918, loss_ce: 0.258548
[21:11:14.194] iteration 1024 : loss : 0.240761, loss_ce: 0.292832
[21:11:14.455] iteration 1025 : loss : 0.347441, loss_ce: 0.372391
[21:11:14.714] iteration 1026 : loss : 0.243849, loss_ce: 0.193850
[21:11:14.971] iteration 1027 : loss : 0.157921, loss_ce: 0.127479
[21:11:15.232] iteration 1028 : loss : 0.180535, loss_ce: 0.189315
[21:11:15.508] iteration 1029 : loss : 0.185368, loss_ce: 0.203396
[21:11:15.803] iteration 1030 : loss : 0.176315, loss_ce: 0.214916
[21:11:16.093] iteration 1031 : loss : 0.298845, loss_ce: 0.320684
[21:11:16.360] iteration 1032 : loss : 0.192541, loss_ce: 0.183718
